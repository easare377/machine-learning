{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "su00atkqqzjZ",
    "outputId": "ada55cad-f86a-4919-bc39-a746d0b0b501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 87.9MB 359kB/s \n",
      "\u001b[K     |████████████████████████████████| 501kB 43.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 3.1MB 34.2MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow==2.0.0-beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-IF3LjvXqdJi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import unicodedata\n",
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "cUoGvxNddFHh",
    "outputId": "7e1b86b4-0462-4653-fb0c-35b3719f760d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "44g54wKWqdJp",
    "outputId": "112f25af-1c1d-4e1a-9869-e5ee602d5366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.1\n"
     ]
    }
   ],
   "source": [
    "keras = tf.keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "DEed-KleNdUK",
    "outputId": "4a4373cb-9ab9-4fc5-b654-b5bb8b6cbd65"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.manythings.org/anki/fra-eng.zip\n",
    "!unzip  fra-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHgfCZXVqdJu"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSK6zPRUqdJz"
   },
   "outputs": [],
   "source": [
    "class Lang(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2int = {}\n",
    "        self.word2count = {}\n",
    "        self.int2word = {0 : \"SOS\", 1 : \"EOS\"}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2int:\n",
    "            self.word2int[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.int2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "            \n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8UujikttqdJ7"
   },
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) \\\n",
    "                   if unicodedata.category(c) != \"Mn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sb0sLusAqdKA"
   },
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    \n",
    "    s = re.sub(r\"([!.?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z?.!]+\", \" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbvFe0iqqdKF"
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    with open(\"fra.txt\",'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # pairs = [[normalizeString(pair) for pair in\n",
    "    #           line.strip().split('\\t')] for line in lines]\n",
    "    pairs = []\n",
    "    for x in lines:\n",
    "        pair = x.split('\\t')\n",
    "        pairs.append([pair[0], pair[1]])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "26fM5LRUqdKJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Calm down.', 'Du calme.'], ['Calm down.', 'Tranquille.']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = load_dataset()\n",
    "pairs[856:858]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Go.', 'Va !'],\n",
       " ['Go.', 'Marche.'],\n",
       " ['Go.', 'Bouge !'],\n",
       " ['Hi.', 'Salut !'],\n",
       " ['Hi.', 'Salut.'],\n",
       " ['Run!', 'Coursâ€¯!'],\n",
       " ['Run!', 'Courezâ€¯!'],\n",
       " ['Run!', 'Prenez vos jambes Ã\\xa0 vos cous !'],\n",
       " ['Run!', 'File !'],\n",
       " ['Run!', 'Filez !'],\n",
       " ['Run!', 'Cours !'],\n",
       " ['Run!', 'Fuyez !'],\n",
       " ['Run!', 'Fuyons !'],\n",
       " ['Run.', 'Coursâ€¯!'],\n",
       " ['Run.', 'Courezâ€¯!'],\n",
       " ['Run.', 'Prenez vos jambes Ã\\xa0 vos cous !'],\n",
       " ['Run.', 'File !'],\n",
       " ['Run.', 'Filez !'],\n",
       " ['Run.', 'Cours !'],\n",
       " ['Run.', 'Fuyez !'],\n",
       " ['Run.', 'Fuyons !'],\n",
       " ['Who?', 'Qui ?'],\n",
       " ['Wow!', 'Ã‡a alorsâ€¯!'],\n",
       " ['Duck!', 'Ã€ terreÂ\\xa0!'],\n",
       " ['Duck!', 'Baisse-toiÂ\\xa0!'],\n",
       " ['Duck!', 'Baissez-vousÂ\\xa0!'],\n",
       " ['Fire!', 'Au feu !'],\n",
       " ['Help!', \"Ã€ l'aideâ€¯!\"],\n",
       " ['Hide.', 'Cache-toi.'],\n",
       " ['Hide.', 'Cachez-vous.'],\n",
       " ['Jump!', 'Saute.'],\n",
       " ['Jump.', 'Saute.'],\n",
       " ['Stop!', 'Ã‡a suffitâ€¯!'],\n",
       " ['Stop!', 'Stopâ€¯!'],\n",
       " ['Stop!', 'ArrÃªte-toi !'],\n",
       " ['Wait!', 'Attends !'],\n",
       " ['Wait!', 'Attendez !'],\n",
       " ['Wait!', 'Attendez.'],\n",
       " ['Wait.', 'Attends !'],\n",
       " ['Wait.', 'Attendez !'],\n",
       " ['Wait.', 'Attends.'],\n",
       " ['Wait.', 'Attendez.'],\n",
       " ['Begin.', 'Commencez.'],\n",
       " ['Begin.', 'Commence.'],\n",
       " ['Go on.', 'Poursuis.'],\n",
       " ['Go on.', 'Continuez.'],\n",
       " ['Go on.', 'Poursuivez.'],\n",
       " ['Hello!', 'Bonjour !'],\n",
       " ['Hello!', 'Salut !'],\n",
       " ['I see.', 'Je comprends.'],\n",
       " ['I see.', 'Aha.'],\n",
       " ['I try.', \"J'essaye.\"],\n",
       " ['I won!', \"J'ai gagnÃ© !\"],\n",
       " ['I won!', \"Je l'ai emportÃ© !\"],\n",
       " ['I won.', 'Jâ€™ai gagnÃ©.'],\n",
       " ['Oh no!', 'Oh non !'],\n",
       " ['Relax.', 'Calme-toi.'],\n",
       " ['Relax.', 'DÃ©tends-toiâ€¯!'],\n",
       " ['Relax.', 'DÃ©tendez-vousâ€¯!'],\n",
       " ['Relax.', 'Relaxe, Maxâ€¯!'],\n",
       " ['Relax.', 'Cool, Raoulâ€¯!'],\n",
       " ['Relax.', 'Du calmeâ€¯!'],\n",
       " ['Relax.', 'Relaxe !'],\n",
       " ['Relax.', 'Calmez-vous !'],\n",
       " ['Relax.', 'DÃ©tends-toi.'],\n",
       " ['Relax.', 'DÃ©tends-toi !'],\n",
       " ['Relax.', 'Du calme.'],\n",
       " ['Relax.', 'Tranquille.'],\n",
       " ['Smile.', 'Souriezâ€¯!'],\n",
       " ['Smile.', 'Souris pour la camÃ©ra.'],\n",
       " ['Smile.', 'Souriezâ€‰!'],\n",
       " ['Sorry?', 'Pardon ?'],\n",
       " ['Attack!', 'Attaque !'],\n",
       " ['Attack!', 'Attaquez !'],\n",
       " ['Attack!', \"Ã€ l'attaque !\"],\n",
       " ['Buy it.', 'Achetez-la !'],\n",
       " ['Buy it.', 'AchÃ¨te-le !'],\n",
       " ['Buy it.', 'Achetez-le !'],\n",
       " ['Buy it.', 'AchÃ¨te-la !'],\n",
       " ['Cheers!', 'SantÃ© !'],\n",
       " ['Cheers!', 'Ã€ votre santÃ© !'],\n",
       " ['Cheers!', 'Merci !'],\n",
       " ['Cheers!', 'Tchin-tchin !'],\n",
       " ['Eat it.', 'Mangez-le.'],\n",
       " ['Eat it.', 'Mange-le.'],\n",
       " ['Get up.', 'LÃ¨ve-toi.'],\n",
       " ['Get up.', 'LÃ¨ve-toi !'],\n",
       " ['Get up.', 'Debout.'],\n",
       " ['Go now.', 'Va, maintenant.'],\n",
       " ['Go now.', 'Allez-y maintenant.'],\n",
       " ['Go now.', 'Vas-y maintenant.'],\n",
       " ['Got it!', \"J'ai pigÃ© !\"],\n",
       " ['Got it!', 'Compris !'],\n",
       " ['Got it!', 'Aha !'],\n",
       " ['Got it?', 'PigÃ©â€¯?'],\n",
       " ['Got it?', 'Comprisâ€¯?'],\n",
       " ['Got it?', \"T'as captÃ©â€¯?\"],\n",
       " ['Hop in.', 'Monte.'],\n",
       " ['Hop in.', 'Montez.'],\n",
       " ['Hug me.', 'Serre-moi dans tes bras !'],\n",
       " ['Hug me.', 'Serrez-moi dans vos bras !'],\n",
       " ['I fell.', 'Je suis tombÃ©e.'],\n",
       " ['I fell.', 'Je suis tombÃ©.'],\n",
       " ['I fled.', \"J'ai fui.\"],\n",
       " ['I knit.', 'Je tricote.'],\n",
       " ['I know.', 'Je sais.'],\n",
       " ['I left.', 'Je suis parti.'],\n",
       " ['I left.', 'Je suis partie.'],\n",
       " ['I lied.', \"J'ai menti.\"],\n",
       " ['I lost.', \"J'ai perdu.\"],\n",
       " ['I paid.', 'Je payais.'],\n",
       " ['I paid.', 'Je payai.'],\n",
       " ['I paid.', 'Jâ€™ai payÃ©.'],\n",
       " ['I quit.', \"J'arrÃªte.\"],\n",
       " ['I quit.', \"J'ai arrÃªtÃ©.\"],\n",
       " [\"I'm 19.\", \"J'ai 19 ans.\"],\n",
       " [\"I'm OK.\", 'Je vais bien.'],\n",
       " [\"I'm OK.\", 'Ã‡a va.'],\n",
       " ['Listen.', 'Ã‰coutez !'],\n",
       " ['No way!', \"C'est pas possibleâ€¯!\"],\n",
       " ['No way!', 'Impossibleâ€¯!'],\n",
       " ['No way!', 'Hors de questionâ€¯!'],\n",
       " ['No way!', 'En aucun cas.'],\n",
       " ['No way!', 'Sans faÃ§onsâ€¯!'],\n",
       " ['No way!', \"C'est hors de question !\"],\n",
       " ['No way!', \"Il n'en est pas question !\"],\n",
       " ['No way!', \"C'est exclu !\"],\n",
       " ['No way!', 'En aucune maniÃ¨re !'],\n",
       " ['No way!', 'Hors de question !'],\n",
       " ['Really?', 'Vraimentâ€¯?'],\n",
       " ['Really?', 'Vrai ?'],\n",
       " ['Really?', 'Ah bon ?'],\n",
       " ['Really?', 'Ah vraiment ?'],\n",
       " ['Really?', 'Vraiment ?'],\n",
       " ['Thanks!', 'Merci !'],\n",
       " ['Thanks.', 'Merci !'],\n",
       " ['Thanks.', 'Merci.'],\n",
       " ['Try it.', 'Essaie.'],\n",
       " ['Try it.', 'Essayez.'],\n",
       " ['Try it.', 'Essaye.'],\n",
       " ['We try.', 'On essaye.'],\n",
       " ['We won.', 'Nous avons gagnÃ©.'],\n",
       " ['We won.', 'Nous gagnÃ¢mes.'],\n",
       " ['We won.', \"Nous l'avons emportÃ©.\"],\n",
       " ['We won.', \"Nous l'emportÃ¢mes.\"],\n",
       " ['Ask Tom.', 'Demande Ã\\xa0 Tom.'],\n",
       " ['Ask him.', 'Demande-lui.'],\n",
       " ['Awesome!', 'Fantastiqueâ€¯!'],\n",
       " ['Awesome!', 'Sensass !'],\n",
       " ['Be calm.', 'Sois calme !'],\n",
       " ['Be calm.', 'Soyez calme !'],\n",
       " ['Be calm.', 'Soyez calmes !'],\n",
       " ['Be cool.', 'Sois dÃ©tendu !'],\n",
       " ['Be fair.', 'Sois juste !'],\n",
       " ['Be fair.', 'Soyez juste !'],\n",
       " ['Be fair.', 'Soyez justes !'],\n",
       " ['Be fair.', 'Sois Ã©quitable !'],\n",
       " ['Be fair.', 'Soyez Ã©quitable !'],\n",
       " ['Be fair.', 'Soyez Ã©quitables !'],\n",
       " ['Be fair.', 'Sois honnÃªte.'],\n",
       " ['Be fair.', 'Sois sincÃ¨re.'],\n",
       " ['Be fair.', 'Soyez honnÃªtes.'],\n",
       " ['Be kind.', 'Sois gentil.'],\n",
       " ['Be nice.', 'Sois gentil !'],\n",
       " ['Be nice.', 'Sois gentille !'],\n",
       " ['Be nice.', 'Soyez gentil !'],\n",
       " ['Be nice.', 'Soyez gentille !'],\n",
       " ['Be nice.', 'Soyez gentils !'],\n",
       " ['Be nice.', 'Soyez gentilles !'],\n",
       " ['Beat it.', 'Va te faire foutre !'],\n",
       " ['Beat it.', 'DÃ©gageâ€¯!'],\n",
       " ['Beat it.', 'Casse-toi.'],\n",
       " ['Beat it.', 'Pars !'],\n",
       " ['Beat it.', 'Foutez le camp !'],\n",
       " ['Beat it.', 'Fous le camp !'],\n",
       " ['Beat it.', \"Pars d'ici.\"],\n",
       " ['Beat it.', \"Va t'en !\"],\n",
       " ['Beat it.', 'Disparais !'],\n",
       " ['Beat it.', 'Fiche le camp.'],\n",
       " ['Beat it.', 'Tire-toi de lÃ\\xa0.'],\n",
       " ['Beat it.', 'Casse-toi de lÃ\\xa0.'],\n",
       " ['Beat it.', 'Oust !'],\n",
       " ['Beat it.', 'DÃ©gage.'],\n",
       " ['Beat it.', \"Fiche le camp d'ici.\"],\n",
       " ['Beat it.', 'DÃ©guerpissez.'],\n",
       " ['Beat it.', 'Bouge !'],\n",
       " ['Beat it.', 'DÃ©campe !'],\n",
       " ['Burn it.', 'BrÃ»lez-le.'],\n",
       " ['Burn it.', 'BrÃ»lez-la.'],\n",
       " ['Burn it.', 'BrÃ»le-la.'],\n",
       " ['Burn it.', 'BrÃ»le-le.'],\n",
       " ['Bury it.', 'Enterrez-le.'],\n",
       " ['Bury it.', 'Enterre-le.'],\n",
       " ['Bury it.', 'Enterrez-la.'],\n",
       " ['Bury it.', 'Enterre-la.'],\n",
       " ['Call me.', 'Appelle-moi !'],\n",
       " ['Call me.', 'Appelez-moiÂ\\xa0!'],\n",
       " ['Call us.', 'Appelle-nous !'],\n",
       " ['Call us.', 'Appelez-nous !'],\n",
       " ['Come in.', 'Entrezâ€¯!'],\n",
       " ['Come in.', 'Entre.'],\n",
       " ['Come in.', 'Entre !'],\n",
       " ['Come in.', 'Entrez !'],\n",
       " ['Come on!', 'Allezâ€¯!'],\n",
       " ['Come on!', 'En avantâ€¯!'],\n",
       " ['Come on!', 'Allons !'],\n",
       " ['Come on!', \"C'est pas vrai, dis !\"],\n",
       " ['Come on!', 'ViensÂ\\xa0!'],\n",
       " ['Come on!', 'Venezâ€¯!'],\n",
       " ['Come on!', 'Secouez-vous !'],\n",
       " ['Come on!', 'Secoue-toi !'],\n",
       " ['Come on!', 'Allez, on y vaÂ\\xa0!'],\n",
       " ['Come on.', 'Allez !'],\n",
       " ['Come on.', 'ViensÂ\\xa0!'],\n",
       " ['Come on.', 'Venezâ€¯!'],\n",
       " ['Drop it!', 'Laisse tomber !'],\n",
       " ['Drop it!', 'Laissez tomber !'],\n",
       " ['Drop it!', 'Laisse-le tomber !'],\n",
       " ['Drop it!', 'Laissez-le tomber !'],\n",
       " ['Fold it.', 'Pliez-le.'],\n",
       " ['Fold it.', 'Plie-le.'],\n",
       " ['Fold it.', 'Pliez-la.'],\n",
       " ['Fold it.', 'Plie-la.'],\n",
       " ['Get Tom.', 'Va chercher Tom.'],\n",
       " ['Get out!', 'Sors.'],\n",
       " ['Get out!', 'Sortezâ€¯!'],\n",
       " ['Get out!', 'DÃ©gageâ€¯!'],\n",
       " ['Get out!', 'Disparaisâ€¯!'],\n",
       " ['Get out!', 'Casse-toi.'],\n",
       " ['Get out!', 'DÃ©gagez !'],\n",
       " ['Get out!', 'Sors !'],\n",
       " ['Get out!', 'Sortez !'],\n",
       " ['Get out!', 'DÃ©gage !'],\n",
       " ['Get out!', 'Disparais !'],\n",
       " ['Get out!', 'Du balai !'],\n",
       " ['Get out!', 'Fiche le camp.'],\n",
       " ['Get out!', 'Oust !'],\n",
       " ['Get out!', \"Vers l'extÃ©rieur !\"],\n",
       " ['Get out!', 'Fichez le camp !'],\n",
       " ['Get out!', 'Sortez.'],\n",
       " ['Get out!', 'DÃ©campez !'],\n",
       " ['Get out!', 'DÃ©campe !'],\n",
       " ['Get out.', 'Sors.'],\n",
       " ['Get out.', 'Sortezâ€¯!'],\n",
       " ['Get out.', 'DÃ©gageâ€¯!'],\n",
       " ['Get out.', 'Disparaisâ€¯!'],\n",
       " ['Get out.', 'Casse-toi.'],\n",
       " ['Get out.', 'DÃ©gagez !'],\n",
       " ['Get out.', 'Sors !'],\n",
       " ['Get out.', 'Sortez !'],\n",
       " ['Get out.', 'Disparais !'],\n",
       " ['Get out.', 'Fiche le camp.'],\n",
       " ['Get out.', 'Oust !'],\n",
       " ['Get out.', 'Sortez.'],\n",
       " ['Get out.', 'Bouge !'],\n",
       " ['Get out.', 'DÃ©campez !'],\n",
       " ['Get out.', 'DÃ©campe !'],\n",
       " ['Go away!', 'DÃ©gageâ€¯!'],\n",
       " ['Go away!', 'Pars !'],\n",
       " ['Go away!', 'Allez-vous en !'],\n",
       " ['Go away!', 'DÃ©guerpissez.'],\n",
       " ['Go away!', 'Cassez-vous.'],\n",
       " ['Go away!', 'Bouge !'],\n",
       " ['Go away!', 'DÃ©campez !'],\n",
       " ['Go away!', 'DÃ©campe !'],\n",
       " ['Go away.', 'Va te faire foutre !'],\n",
       " ['Go away.', 'Pars !'],\n",
       " ['Go away.', 'DÃ©gage !'],\n",
       " ['Go away.', 'Fous le camp !'],\n",
       " ['Go away.', \"Pars d'ici.\"],\n",
       " ['Go away.', \"Va t'en !\"],\n",
       " ['Go away.', 'Disparais !'],\n",
       " ['Go away.', 'DÃ©guerpissez.'],\n",
       " ['Go away.', 'Cassez-vous.'],\n",
       " ['Go away.', 'Bouge !'],\n",
       " ['Go away.', 'DÃ©campez !'],\n",
       " ['Go away.', 'DÃ©campe !'],\n",
       " ['Go back.', 'Recule.'],\n",
       " ['Go home.', 'Rentrez Ã\\xa0 la maison.'],\n",
       " ['Go home.', 'Rentre Ã\\xa0 la maison.'],\n",
       " ['Go home.', 'Rentre chez toi.'],\n",
       " ['Go home.', 'Rentrez chez vous.'],\n",
       " ['Go slow.', 'Va doucement !'],\n",
       " ['Go slow.', 'Allez doucement !'],\n",
       " ['Goodbye!', 'Adieu !'],\n",
       " ['Goodbye!', 'Ã€ la revoyure.'],\n",
       " ['Goodbye!', 'Ciao.'],\n",
       " ['Hang on!', 'Attends un peu !'],\n",
       " ['Hang on!', 'Attendez un peu !'],\n",
       " ['Hang on!', 'Attendez.'],\n",
       " ['Hang on.', 'Tiens bon !'],\n",
       " ['Hang on.', 'Tenez bon !'],\n",
       " ['Hang on.', 'Attendez.'],\n",
       " ['He left.', 'Il est parti.'],\n",
       " ['He quit.', 'Il laissa tomber.'],\n",
       " ['He quit.', 'Il a laissÃ© tomber.'],\n",
       " ['He runs.', 'Il court.'],\n",
       " ['Help me!', 'Aide-moi !'],\n",
       " ['Help me.', \"Ã€ l'aideâ€¯!\"],\n",
       " ['Help me.', 'Aide-moi.'],\n",
       " ['Help me.', 'Aidez-moi.'],\n",
       " ['Help me.', 'Aide-moi !'],\n",
       " ['Help us.', 'Aidez-nous !'],\n",
       " ['Help us.', 'Aide-nous !'],\n",
       " ['Hold it!', 'Ne bouge plus !'],\n",
       " ['Hold it!', 'Ne bougez plus !'],\n",
       " ['Hold it!', 'Restez oÃ¹ vous Ãªtes !'],\n",
       " ['Hold it!', 'Attendez.'],\n",
       " ['Hold on.', 'Ne quittez pas.'],\n",
       " ['Hold on.', 'Ne quitte pas !'],\n",
       " ['How sad!', \"Comme c'est triste.\"],\n",
       " ['Hug Tom.', 'Fais un cÃ¢lin Ã\\xa0 Tom.'],\n",
       " ['I agree.', 'Je suis du mÃªme avis.'],\n",
       " ['I cried.', \"J'ai pleurÃ©.\"],\n",
       " ['I dozed.', 'Je me suis assoupi.'],\n",
       " ['I dozed.', 'Je me suis assoupie.'],\n",
       " ['I drive.', 'Je conduis.'],\n",
       " ['I drove.', 'Je conduisis.'],\n",
       " ['I fired.', \"J'ai tirÃ©.\"],\n",
       " ['I froze.', 'Je me suis figÃ©.'],\n",
       " ['I froze.', 'Je me suis figÃ©e.'],\n",
       " ['I smoke.', 'Je fume.'],\n",
       " ['I snore.', 'Je ronfle.'],\n",
       " ['I stink.', 'Je pue.'],\n",
       " ['I stood.', 'Je me suis tenu debout.'],\n",
       " ['I stood.', 'Je me suis tenue debout.'],\n",
       " ['I swore.', 'Jâ€™ai promis.'],\n",
       " ['I swore.', 'Jâ€™ai jurÃ©.'],\n",
       " ['I tried.', \"J'essayai.\"],\n",
       " ['I tried.', \"J'ai essayÃ©.\"],\n",
       " ['I tried.', \"J'ai tentÃ©.\"],\n",
       " ['I waved.', 'Jâ€™ai fait signe.'],\n",
       " [\"I'll go.\", \"J'irai.\"],\n",
       " [\"I'm Tom.\", 'Je suis Tom.'],\n",
       " [\"I'm fat.\", 'Je suis gras.'],\n",
       " [\"I'm fat.\", 'Je suis gros.'],\n",
       " [\"I'm fit.\", 'Je suis en forme.'],\n",
       " [\"I'm hit!\", 'Je suis touchÃ© !'],\n",
       " [\"I'm hit!\", 'Je suis touchÃ©e !'],\n",
       " [\"I'm ill.\", 'Je suis malade.'],\n",
       " [\"I'm sad.\", 'Je suis triste.'],\n",
       " [\"I'm sad.\", \"J'ai un coup de cafard.\"],\n",
       " [\"I'm sad.\", 'Je suis malheureux.'],\n",
       " [\"I'm shy.\", 'Je suis timide.'],\n",
       " [\"I'm wet.\", 'Je suis mouillÃ©.'],\n",
       " [\"I'm wet.\", 'Je suis mouillÃ©e.'],\n",
       " [\"It's me!\", \"C'est bibiâ€¯!\"],\n",
       " ['Join us.', 'Joignez-vous.'],\n",
       " ['Join us.', 'Joignez-vous Ã\\xa0 nous.'],\n",
       " ['Keep it.', 'Garde-le !'],\n",
       " ['Keep it.', 'Gardez-le !'],\n",
       " ['Kick it.', 'Donne-lui un coup de pied.'],\n",
       " ['Kick it.', 'Donnez-lui un coup de pied.'],\n",
       " ['Kill it.', 'Tuez-le.'],\n",
       " ['Kill it.', 'Tue-le.'],\n",
       " ['Kill it.', 'Tue-la.'],\n",
       " ['Kill it.', 'Tuez-la.'],\n",
       " ['Kiss me.', 'Embrasse-moi.'],\n",
       " ['Kiss me.', 'Embrassez-moi.'],\n",
       " ['Lie low.', 'Ã€ terre !'],\n",
       " ['Lie low.', 'Au sol !'],\n",
       " ['Lock it.', 'Verrouillez-le.'],\n",
       " ['Lock it.', 'Verrouille-le.'],\n",
       " ['Lock it.', 'Verrouillez-la.'],\n",
       " ['Lock it.', 'Verrouille-la.'],\n",
       " ['Me, too.', 'Moi aussi.'],\n",
       " ['Move on.', 'Passez Ã\\xa0 autre chose.'],\n",
       " ['Move on.', 'Passe Ã\\xa0 autre chose.'],\n",
       " ['Open it.', 'Ouvrez-le.'],\n",
       " ['Open it.', 'Ouvre-le.'],\n",
       " ['Open it.', 'Ouvre-la.'],\n",
       " ['Open it.', 'Ouvrez-la.'],\n",
       " ['Open up.', 'Ouvre-moiâ€¯!'],\n",
       " ['Open up.', 'Ouvre.'],\n",
       " ['Pair up.', 'Faites Ã©quipe.'],\n",
       " ['Perfect!', 'Parfaitâ€¯!'],\n",
       " ['Pull it.', 'Tirez dessus.'],\n",
       " ['Pull it.', 'Tire dessus.'],\n",
       " ['Push it.', 'Appuie dessus.'],\n",
       " ['Push it.', 'Poussez-le.'],\n",
       " ['Push it.', 'Pousse-le.'],\n",
       " ['Push it.', 'Poussez-la.'],\n",
       " ['Push it.', 'Pousse-la.'],\n",
       " ['See you!', 'Ã€ plus tard !'],\n",
       " ['See you!', 'Ã€ bientÃ´t !'],\n",
       " ['See you!', 'Ã€ la prochaine !'],\n",
       " ['See you!', 'Ciao.'],\n",
       " ['See you.', 'Ã€ plus.'],\n",
       " ['See you.', 'Ciao.'],\n",
       " ['Show me.', 'Montre-moi !'],\n",
       " ['Show me.', 'Montrez-moi !'],\n",
       " ['Shut up!', 'Taisez-vousâ€¯!'],\n",
       " ['Shut up!', 'Ferme-laâ€¯!'],\n",
       " ['Shut up!', 'Tais-toi !'],\n",
       " ['Shut up!', 'Ferme-la !'],\n",
       " ['Shut up!', 'La ferme !'],\n",
       " ['Shut up!', 'Bouclez-la !'],\n",
       " ['Sign up.', 'Inscrivez-vous.'],\n",
       " ['Sign up.', 'Inscris-toi.'],\n",
       " ['Skip it.', 'Pas grave.'],\n",
       " ['So long.', 'Ã€ plus tard !'],\n",
       " ['Take it.', 'Prends-leâ€¯!'],\n",
       " ['Take it.', 'Prenez-leâ€¯!'],\n",
       " ['Take it.', 'Prends-le !'],\n",
       " ['Take it.', 'Prenez-le !'],\n",
       " ['Take it.', 'Prenez-le.'],\n",
       " ['Tell me.', 'Dis-moi !'],\n",
       " ['Tell me.', 'Dites-moi !'],\n",
       " ['Tom won.', 'Tom a gagnÃ©.'],\n",
       " ['Wake up!', 'RÃ©veille-toiâ€¯!'],\n",
       " ['Wake up!', 'RÃ©veille-toi !'],\n",
       " ['Wake up!', 'RÃ©veillez-vous !'],\n",
       " ['Wake up.', 'RÃ©veille-toi !'],\n",
       " ['Wake up.', 'RÃ©veillez-vous !'],\n",
       " ['Wash up.', 'Lave-toi !'],\n",
       " ['Wash up.', 'Lavez-vous !'],\n",
       " ['We care.', 'Nous nous en soucions.'],\n",
       " ['We know.', 'Nous savons.'],\n",
       " ['We lost.', 'Nous perdÃ®mes.'],\n",
       " ['We lost.', 'Nous avons perdu.'],\n",
       " ['We lost.', 'Nous fÃ»mes battus.'],\n",
       " ['We lost.', 'Nous fÃ»mes battues.'],\n",
       " ['We lost.', 'Nous fÃ»mes dÃ©faits.'],\n",
       " ['We lost.', 'Nous fÃ»mes dÃ©faites.'],\n",
       " ['We lost.', 'Nous avons Ã©tÃ© dÃ©faits.'],\n",
       " ['We lost.', 'Nous avons Ã©tÃ© dÃ©faites.'],\n",
       " ['We lost.', 'Nous avons Ã©tÃ© battus.'],\n",
       " ['We lost.', 'Nous avons Ã©tÃ© battues.'],\n",
       " ['Welcome.', 'Bienvenueâ€¯!'],\n",
       " ['Welcome.', 'Soyez le bienvenu !'],\n",
       " ['Who ran?', 'Qui couraitÂ\\xa0?'],\n",
       " ['Who won?', 'Qui a gagnÃ© ?'],\n",
       " ['Who won?', \"Qui l'a emportÃ© ?\"],\n",
       " ['You run.', 'Tu cours.'],\n",
       " ['You win.', 'Vous avez gagnÃ©.'],\n",
       " ['Aim high.', 'Visez haut.'],\n",
       " ['Aim high.', 'Vise haut.'],\n",
       " ['Am I fat?', 'Suis-je gros ?'],\n",
       " ['Am I fat?', 'Suis-je grosse ?'],\n",
       " ['Ask them.', 'Demande-leur.'],\n",
       " ['Ask them.', 'Demandez-leur.'],\n",
       " ['Back off!', 'Reculeâ€‰!'],\n",
       " ['Back off!', 'Reculez.'],\n",
       " ['Back off!', 'Cassez-vous.'],\n",
       " ['Back off.', 'Reculeâ€‰!'],\n",
       " ['Back off.', 'Reculez.'],\n",
       " ['Back off.', 'Retire-toiâ€‰!'],\n",
       " ['Back off.', 'Retirez-vous.'],\n",
       " ['Back off.', 'Cassez-vous.'],\n",
       " ['Be a man.', 'Sois un homme !'],\n",
       " ['Be a man.', 'Soyez un homme !'],\n",
       " ['Be brave.', 'Soyez courageux !'],\n",
       " ['Be brief.', 'Soyez bref.'],\n",
       " ['Be brief.', 'Sois bref.'],\n",
       " ['Be brief.', 'Sois brÃ¨ve.'],\n",
       " ['Be brief.', 'Soyez brÃ¨ve.'],\n",
       " ['Be brief.', 'Soyez brefs.'],\n",
       " ['Be brief.', 'Soyez brÃ¨ves.'],\n",
       " ['Be still.', 'Sois calme !'],\n",
       " ['Be still.', 'Soyez calme !'],\n",
       " ['Be still.', 'Soyez calmes !'],\n",
       " ['Beats me.', 'Aucune idÃ©e.'],\n",
       " ['Beats me.', \"J'en sais foutre rien.\"],\n",
       " ['Call Tom.', 'Appelle Tom.'],\n",
       " ['Call Tom.', 'Appelez Tom.'],\n",
       " ['Cheer up!', 'Courageâ€¯!'],\n",
       " ['Cool off!', 'DÃ©tends-toiâ€¯!'],\n",
       " ['Cuff him.', 'Menottez-le.'],\n",
       " ['Drive on.', 'Avance !'],\n",
       " ['Drive on.', 'Avancez !'],\n",
       " ['Drive on.', 'Continue Ã\\xa0 rouler !'],\n",
       " ['Drive on.', 'Continuez Ã\\xa0 rouler !'],\n",
       " ['Find Tom.', 'Trouve Tom.'],\n",
       " ['Find Tom.', 'Trouvez Tom.'],\n",
       " ['Fix this.', 'RÃ©parez ceci.'],\n",
       " ['Fix this.', 'RÃ©pare Ã§a.'],\n",
       " ['Get away!', 'DÃ©gageâ€¯!'],\n",
       " ['Get away!', 'Casse-toi.'],\n",
       " ['Get away!', 'Pars !'],\n",
       " ['Get away!', 'DÃ©gage !'],\n",
       " ['Get away!', 'Fous le camp !'],\n",
       " ['Get away!', \"Pars d'ici.\"],\n",
       " ['Get away!', \"Va t'en !\"],\n",
       " ['Get away!', 'Ã‰carte-toi !'],\n",
       " ['Get away!', 'Disparais !'],\n",
       " ['Get away!', 'Allez-vous en !'],\n",
       " ['Get away!', 'Fiche le camp.'],\n",
       " ['Get away!', 'Tire-toi de lÃ\\xa0.'],\n",
       " ['Get away!', 'DÃ©gage.'],\n",
       " ['Get away!', \"Va-t'en !\"],\n",
       " ['Get away!', \"Criss ton camp d'icit !\"],\n",
       " ['Get away!', 'Fichez le camp.'],\n",
       " ['Get away!', 'DÃ©guerpissez.'],\n",
       " ['Get away!', 'Cassez-vous.'],\n",
       " ['Get away!', 'Barrez-vous.'],\n",
       " ['Get away!', 'Barre-toi.'],\n",
       " ['Get away!', 'Va-tâ€™en !'],\n",
       " ['Get away!', 'Bouge !'],\n",
       " ['Get away!', 'DÃ©campez !'],\n",
       " ['Get away!', 'DÃ©campe !'],\n",
       " ['Get away.', 'Pars.'],\n",
       " ['Get away.', 'Partez.'],\n",
       " ['Get down!', 'LÃ¢che-toi !'],\n",
       " ['Get down!', 'Ã€ terre !'],\n",
       " ['Get down!', 'Au sol !'],\n",
       " ['Get down!', 'Descends.'],\n",
       " ['Get down.', 'Descends !'],\n",
       " ['Get down.', 'Descendez !'],\n",
       " ['Get down.', 'LÃ¢che-toi !'],\n",
       " ['Get down.', 'LÃ¢chez-vous !'],\n",
       " ['Get down.', 'Ã€ terre !'],\n",
       " ['Get down.', 'Au sol !'],\n",
       " ['Get down.', 'Descends.'],\n",
       " ['Get lost!', \"Va voir ailleurs si j'y suisâ€¯!\"],\n",
       " ['Get lost!', 'DÃ©gageâ€¯!'],\n",
       " ['Get lost!', 'Va au diable !'],\n",
       " ['Get lost!', 'DÃ©guerpissez.'],\n",
       " ['Get lost!', 'Cassez-vous.'],\n",
       " ['Get lost!', 'Bouge !'],\n",
       " ['Get lost!', 'DÃ©campez !'],\n",
       " ['Get lost!', 'DÃ©campe !'],\n",
       " ['Get lost.', 'Fiche le camp.'],\n",
       " ['Get lost.', 'Fichez le camp.'],\n",
       " ['Get lost.', 'DÃ©guerpissez.'],\n",
       " ['Get lost.', 'Cassez-vous.'],\n",
       " ['Get lost.', 'Bouge !'],\n",
       " ['Get lost.', 'DÃ©campez !'],\n",
       " ['Get lost.', 'DÃ©campe !'],\n",
       " ['Get real!', 'Sois rÃ©aliste !'],\n",
       " ['Go ahead!', 'Allezâ€¯!'],\n",
       " ['Go ahead!', 'Vas-y.'],\n",
       " ['Go ahead!', 'En avantâ€¯!'],\n",
       " ['Go ahead!', 'Va !'],\n",
       " ['Go ahead!', 'Poursuis !'],\n",
       " ['Go ahead!', 'Poursuivez !'],\n",
       " ['Go ahead!', 'Passe devant !'],\n",
       " ['Go ahead!', 'Vas-y !'],\n",
       " ['Go ahead!', 'Allez-y !'],\n",
       " ['Go ahead!', 'Continuez !'],\n",
       " ['Go ahead!', 'Continue !'],\n",
       " ['Go ahead!', 'Allez !'],\n",
       " ['Go ahead!', 'Avance !'],\n",
       " ['Go ahead.', 'Allezâ€¯!'],\n",
       " ['Go ahead.', 'Vas-y.'],\n",
       " ['Go ahead.', 'Va !'],\n",
       " ['Go ahead.', 'Poursuis !'],\n",
       " ['Go ahead.', 'Poursuivez !'],\n",
       " ['Go ahead.', 'Passe devant !'],\n",
       " ['Go ahead.', 'Vas-y !'],\n",
       " ['Go ahead.', 'Allez-y !'],\n",
       " ['Go ahead.', 'Continuez !'],\n",
       " ['Go ahead.', 'Continue !'],\n",
       " ['Go ahead.', 'Allez !'],\n",
       " ['Go ahead.', 'Avance !'],\n",
       " ['Good job!', 'Bien jouÃ©â€¯!'],\n",
       " ['Good job!', 'Bon boulotâ€¯!'],\n",
       " ['Good job!', 'Beau travailâ€¯!'],\n",
       " ['Good job!', 'Bravo !'],\n",
       " ['Grab him.', 'Attrape-le.'],\n",
       " ['Grab him.', 'Attrapez-le.'],\n",
       " ['Have fun.', 'Amuse-toi bien !'],\n",
       " ['Have fun.', 'Amusez-vous bien !'],\n",
       " ['He spoke.', 'Il a parlÃ©.'],\n",
       " ['He spoke.', 'Il a pris la parole.'],\n",
       " ['He spoke.', \"Il s'est exprimÃ©.\"],\n",
       " ['He tries.', 'Il essaye.'],\n",
       " [\"He's wet.\", 'Il est mouillÃ©.'],\n",
       " ['Help Tom.', 'Aide Tom.'],\n",
       " ['Help Tom.', 'Aidez Tom.'],\n",
       " ['Help Tom.', 'Aidez Tom !'],\n",
       " ['Hi, guys.', 'Salut, les mecs !'],\n",
       " ['How cute!', \"Comme c'est mignonâ€¯!\"],\n",
       " ['How cute!', 'Trop mignon !'],\n",
       " ['How cute!', 'Trop mignonne !'],\n",
       " ['How deep?', 'Quelle profondeurâ€¯?'],\n",
       " ['How nice!', 'Comme elle est belleâ€¯!'],\n",
       " ['How nice!', \"Comme c'est chouette !\"],\n",
       " ['How nice!', \"Comme c'est gentil !\"],\n",
       " ['How nice!', \"C'est du joli !\"],\n",
       " ['How nice!', \"Comme c'est agrÃ©able !\"],\n",
       " ['How rude!', 'Quelle grossiÃ¨retÃ© !'],\n",
       " ['How wise!', 'Quelle sagesse !'],\n",
       " ['Hurry up.', 'DÃ©pÃªche-toi.'],\n",
       " ['Hurry up.', 'Grouilleâ€¯!'],\n",
       " ['Hurry up.', 'Pressez-vous !'],\n",
       " ['Hurry up.', 'FiÃ§a !'],\n",
       " ['Hurry up.', 'Magne-toi !'],\n",
       " ['Hurry up.', 'Magnez-vous !'],\n",
       " ['I am Tom.', 'Je suis Tom.'],\n",
       " ['I cursed.', \"J'ai jurÃ©.\"],\n",
       " ['I did OK.', \"Je m'en suis bien sorti.\"],\n",
       " ['I did OK.', \"Je m'en suis bien sortie.\"],\n",
       " ['I did it.', \"Je l'ai fait.\"],\n",
       " ['I did it.', \"C'est moi qui l'ai fait.\"],\n",
       " ['I failed.', \"J'ai Ã©chouÃ©.\"],\n",
       " ['I forgot.', \"J'ai oubliÃ©.\"],\n",
       " ['I get it.', \"J'ai compris.\"],\n",
       " ['I goofed.', \"J'ai fait une gaffe.\"],\n",
       " ['I got it.', \"J'ai compris.\"],\n",
       " ['I got it.', \"J'ai captÃ©.\"],\n",
       " ['I helped.', \"J'ai aidÃ©.\"],\n",
       " ['I jumped.', \"J'ai sautÃ©.\"],\n",
       " ['I looked.', 'Jâ€™ai regardÃ©.'],\n",
       " ['I moaned.', 'Jâ€™ai rÃ¢lÃ©.'],\n",
       " ['I nodded.', 'Jâ€™ai fait signe de la tÃªte.'],\n",
       " ['I obeyed.', 'Jâ€™ai obÃ©i.'],\n",
       " ['I phoned.', 'Je tÃ©lÃ©phonai.'],\n",
       " ['I phoned.', \"J'ai tÃ©lÃ©phonÃ©.\"],\n",
       " ['I refuse.', 'Je refuse.'],\n",
       " ['I refuse.', 'Je le refuse.'],\n",
       " ['I rested.', 'Je me suis reposÃ©.'],\n",
       " ['I rested.', 'Je me suis reposÃ©e.'],\n",
       " ['I saw it.', \"Je l'ai vu.\"],\n",
       " ['I saw it.', 'Je lâ€™ai vu.'],\n",
       " ['I sighed.', 'Jâ€™ai soupirÃ©.'],\n",
       " ['I smiled.', \"J'ai souri.\"],\n",
       " ['I stayed.', 'Je suis restÃ©.'],\n",
       " ['I stayed.', 'Je suis restÃ©e.'],\n",
       " ['I talked.', 'Jâ€™ai parlÃ©.'],\n",
       " ['I use it.', \"Je l'utilise.\"],\n",
       " ['I use it.', \"J'en fais usage.\"],\n",
       " ['I use it.', \"Je m'en sers.\"],\n",
       " [\"I'll pay.\", 'Je paierai.'],\n",
       " [\"I'll pay.\", 'Je paie.'],\n",
       " [\"I'll try.\", 'Je vais essayer.'],\n",
       " [\"I'll try.\", \"J'essaierai.\"],\n",
       " [\"I'm back.\", 'Je suis revenu.'],\n",
       " [\"I'm back.\", 'Me revoilÃ\\xa0.'],\n",
       " [\"I'm bald.\", 'Je suis chauve.'],\n",
       " [\"I'm busy.\", 'Je suis occupÃ©.'],\n",
       " [\"I'm busy.\", 'Je suis occupÃ©e.'],\n",
       " [\"I'm calm.\", 'Je suis calme.'],\n",
       " [\"I'm cold.\", \"J'ai froid.\"],\n",
       " [\"I'm cool.\", 'Je suis dÃ©tendu.'],\n",
       " [\"I'm cool.\", 'Je suis dÃ©tendue.'],\n",
       " [\"I'm deaf.\", 'Je suis sourd.'],\n",
       " [\"I'm deaf.\", 'Je suis sourde.'],\n",
       " [\"I'm done.\", \"J'en ai fini.\"],\n",
       " [\"I'm fair.\", 'Je suis juste.'],\n",
       " [\"I'm fair.\", \"J'ai la peau claire.\"],\n",
       " [\"I'm fair.\", \"J'ai le teint clair.\"],\n",
       " [\"I'm fast.\", 'Je suis rapide.'],\n",
       " [\"I'm fine.\", 'Tout va bien.'],\n",
       " [\"I'm fine.\", 'Je vais bien.'],\n",
       " [\"I'm fine.\", 'Ã‡a va.'],\n",
       " [\"I'm free!\", 'Je suis libre !'],\n",
       " [\"I'm free.\", 'Je suis libre.'],\n",
       " [\"I'm free.\", 'Je suis disponible.'],\n",
       " [\"I'm full.\", 'Je suis repuâ€¯!'],\n",
       " [\"I'm full.\", 'Je suis rassasiÃ©â€¯!'],\n",
       " [\"I'm game.\", \"J'en suis.\"],\n",
       " [\"I'm game.\", 'Je suis de la partie.'],\n",
       " [\"I'm glad.\", 'Je suis content.'],\n",
       " [\"I'm home.\", 'Je suis chez moi.'],\n",
       " [\"I'm late.\", 'Je suis en retard.'],\n",
       " [\"I'm lazy.\", 'Je suis paresseux.'],\n",
       " [\"I'm lazy.\", 'Je suis fainÃ©ant.'],\n",
       " [\"I'm lazy.\", 'Je suis paresseuse.'],\n",
       " [\"I'm lazy.\", 'Je suis fainÃ©ante.'],\n",
       " [\"I'm lost.\", 'Je suis paumÃ©.'],\n",
       " [\"I'm lost.\", 'Je suis perdue.'],\n",
       " [\"I'm okay.\", 'Je vais bien.'],\n",
       " [\"I'm okay.\", 'Je me porte bien.'],\n",
       " [\"I'm rich.\", 'Je suis riche.'],\n",
       " [\"I'm safe.\", 'Je suis en sÃ©curitÃ©.'],\n",
       " [\"I'm sick.\", 'Je suis malade.'],\n",
       " [\"I'm sure.\", \"J'en suis certain.\"],\n",
       " [\"I'm sure.\", 'Je suis certain.'],\n",
       " [\"I'm sure.\", \"J'en suis sÃ»r.\"],\n",
       " [\"I'm sure.\", \"J'en suis sÃ»re.\"],\n",
       " [\"I'm tall.\", 'Je suis grande.'],\n",
       " [\"I'm thin.\", 'Je suis mince.'],\n",
       " [\"I'm tidy.\", 'Je suis ordonnÃ©.'],\n",
       " [\"I'm tidy.\", 'Je suis ordonnÃ©e.'],\n",
       " [\"I'm ugly.\", 'Je suis laid.'],\n",
       " [\"I'm ugly.\", 'Je suis laide.'],\n",
       " [\"I'm weak.\", 'Je suis faible.'],\n",
       " [\"I'm well.\", 'Je vais bien.'],\n",
       " [\"I'm well.\", 'Je me porte bien.'],\n",
       " [\"I've won.\", \"J'ai gagnÃ©.\"],\n",
       " [\"I've won.\", \"Je l'ai emportÃ©.\"],\n",
       " ['It helps.', 'Ã‡a aide.'],\n",
       " ['It hurts.', 'Ã‡a fait mal.'],\n",
       " ['It works.', 'Elle marche.'],\n",
       " ['It works.', 'Ã‡a fonctionne.'],\n",
       " [\"It's Tom.\", \"C'est Tom.\"],\n",
       " [\"It's fun.\", \"C'est marrant.\"],\n",
       " [\"It's fun.\", \"C'est rigolo.\"],\n",
       " [\"It's his.\", \"C'est le sien.\"],\n",
       " [\"It's his.\", \"C'est la sienne.\"],\n",
       " [\"It's new.\", \"C'est nouveau.\"],\n",
       " [\"It's new.\", \"C'est neuf.\"],\n",
       " [\"It's odd.\", \"C'est bizarre.\"],\n",
       " [\"It's red.\", 'Il est rouge.'],\n",
       " [\"It's sad.\", 'Câ€™est triste.'],\n",
       " ['Keep out!', \"DÃ©fense d'entrer.\"],\n",
       " ['Keep out.', \"N'entrez pas.\"],\n",
       " ['Kill Tom.', 'Tuez Tom.'],\n",
       " ['Kill Tom.', 'Tue Tom.'],\n",
       " ['Kiss Tom.', 'Embrasse Tom.'],\n",
       " ['Leave it.', 'Laisse tomber !'],\n",
       " ['Leave it.', 'Laissez tomber !'],\n",
       " ['Leave it.', 'Laisse !'],\n",
       " ['Leave it.', 'Laissez Ã§a.'],\n",
       " ['Leave it.', 'Laisse Ã§a.'],\n",
       " ['Leave me.', 'Laissez-moi !'],\n",
       " ['Leave us.', 'Laisse-nous !'],\n",
       " ['Leave us.', 'Laissez-nous !'],\n",
       " [\"Let's go!\", 'Allons-y !'],\n",
       " [\"Let's go!\", 'Allons !'],\n",
       " [\"Let's go.\", 'Allons-y !'],\n",
       " ['Look out!', 'Attention !'],\n",
       " ['Look out!', 'Faites attentionâ€¯!'],\n",
       " ['Look out!', 'Fais attentionâ€¯!'],\n",
       " ['Look out!', 'Soyez prudente !'],\n",
       " ['Look out!', 'Fais gaffe !'],\n",
       " ['Look out!', 'Faites gaffe !'],\n",
       " ['Look out!', 'Fais attention !'],\n",
       " ['Look out!', 'Regarde donc !'],\n",
       " ['Look out!', 'Faites attention.'],\n",
       " ['Look out!', 'Fais attention.'],\n",
       " ['Marry me.', 'Ã‰pouse-moi !'],\n",
       " ['Marry me.', 'Ã‰pousez-moi !'],\n",
       " ['May I go?', 'Puis-je partir ?'],\n",
       " ['May I go?', 'Puis-je y aller ?'],\n",
       " ['May I go?', \"Puis-je m'y rendre ?\"],\n",
       " ['Now stop!', 'ArrÃªtez-vous maintenantÂ\\xa0!'],\n",
       " ['Now stop!', 'ArrÃªte-toi maintenantÂ\\xa0!'],\n",
       " ['Run away.', 'Fuyez.'],\n",
       " ['Run away.', 'Fuis.'],\n",
       " ['Run away.', 'Enfuyez-vous.'],\n",
       " ['Run away.', 'Enfuis-toi.'],\n",
       " ['Save Tom.', 'Sauve Tom.'],\n",
       " ['Save Tom.', 'Sauvez Tom.'],\n",
       " ['Say what?', 'De quoiâ€¯?'],\n",
       " ['She came.', 'Elle est venue.'],\n",
       " ['She died.', 'Elle est morte.'],\n",
       " ['She left.', 'Elle est partie.'],\n",
       " ['She runs.', 'Elle court.'],\n",
       " ['Sit down!', 'Assieds-toi !'],\n",
       " ['Sit down!', 'Asseyez-vous !'],\n",
       " ['Sit down!', 'Asseyez-vous.'],\n",
       " ['Sit down.', 'Assieds-toi.'],\n",
       " ['Sit down.', 'Asseyez-vous.'],\n",
       " ['Sit here.', 'Assieds-toi ici.'],\n",
       " ['Sit here.', 'Asseyez-vous ici.'],\n",
       " ['Speak up!', 'Parle plus fortâ€¯!'],\n",
       " ['Speak up!', 'Parlez plus fortâ€¯!'],\n",
       " ['Speak up!', 'Parle plus fort !'],\n",
       " ['Speed up.', 'AccÃ©lÃ¨re.'],\n",
       " ['Speed up.', 'AccÃ©lÃ©rez.'],\n",
       " ['Stand up.', 'LÃ¨ve-toi.'],\n",
       " ['Stop Tom.', 'ArrÃªte Tom.'],\n",
       " ['Stop Tom.', 'Stoppez Tom.'],\n",
       " ['Take Tom.', 'Prends Tom.'],\n",
       " ['Taste it.', 'GoÃ»te-le.'],\n",
       " ['Taste it.', 'GoÃ»te-la.'],\n",
       " ['Taste it.', 'GoÃ»tez-le.'],\n",
       " ['Taste it.', 'GoÃ»tez-la.'],\n",
       " ['Tell Tom.', 'Dis-le Ã\\xa0 Tom.'],\n",
       " ['Tell Tom.', 'Informez-en Tom.'],\n",
       " ['Terrific!', 'Fantastiqueâ€¯!'],\n",
       " ['Terrific!', 'GÃ©nialâ€¯!'],\n",
       " ['Terrific!', 'Superâ€¯!'],\n",
       " ['Terrific!', 'Au poilâ€¯!'],\n",
       " ['Terrific!', 'Impeccableâ€¯!'],\n",
       " ['Terrific!', 'Nickelâ€¯!'],\n",
       " ['Terrific!', 'Excellentâ€¯!'],\n",
       " ['Terrific!', 'Magnifiqueâ€¯!'],\n",
       " ['Terrific!', 'Nickel chromeâ€¯!'],\n",
       " ['Terrific!', 'Bien.'],\n",
       " ['Terrific!', 'Formidable !'],\n",
       " ['Terrific!', \"C'est gÃ©nial !\"],\n",
       " ['Terrific!', 'Ã€ la bonne heure !'],\n",
       " ['Terrific!', \"C'est super.\"],\n",
       " ['Terrific!', 'Super !'],\n",
       " ['Terrific!', 'GÃ©nial !'],\n",
       " ['Terrific!', 'Sensass !'],\n",
       " ['They won.', 'Ils gagnÃ¨rent.'],\n",
       " ['They won.', 'Elles gagnÃ¨rent.'],\n",
       " ['They won.', 'Ils ont gagnÃ©.'],\n",
       " ['They won.', 'Elles ont gagnÃ©.'],\n",
       " ['Tom came.', 'Tom est venu.'],\n",
       " ['Tom died.', 'Tom est mort.'],\n",
       " ['Tom knew.', 'Tom savait.'],\n",
       " ['Tom left.', 'Tom est parti.'],\n",
       " ['Tom left.', 'Tom partit.'],\n",
       " ['Tom lied.', 'Tom a menti.'],\n",
       " ['Tom lies.', 'Tom ment.'],\n",
       " ['Tom lost.', 'Tom a perdu.'],\n",
       " ['Tom paid.', 'Tom a payÃ©.'],\n",
       " ['Tom paid.', 'Tom payait.'],\n",
       " ['Tom went.', 'Tom est parti.'],\n",
       " [\"Tom's up.\", 'Tom est debout.'],\n",
       " ['Too late.', 'Trop tard.'],\n",
       " ['Touch it.', 'Touchez-le.'],\n",
       " ['Touch it.', 'Touchez-la.'],\n",
       " ['Touch it.', 'Touche-le.'],\n",
       " ['Touch it.', 'Touche-la.'],\n",
       " ['Trust me.', 'Faites-moi confiance.'],\n",
       " ['Trust me.', 'Fais-moi confiance.'],\n",
       " ['Try some.', 'Essaies-en !'],\n",
       " ['Try some.', 'Essayez-en !'],\n",
       " ['Try some.', 'Essaie.'],\n",
       " ['Try this.', 'Essaie ceci !'],\n",
       " ['Try this.', 'Essayez ceci !'],\n",
       " ['Try this.', 'Essaye ceci.'],\n",
       " ['Use this.', 'Utilise ceci.'],\n",
       " ['Use this.', 'Utilisez ceci.'],\n",
       " ['Use this.', 'Emploie ceci !'],\n",
       " ['Use this.', 'Employez ceci !'],\n",
       " ['Warn Tom.', 'Avertis Tom.'],\n",
       " ['Warn Tom.', 'PrÃ©viens Tom.'],\n",
       " ['Watch me.', 'Regarde-moi !'],\n",
       " ['Watch me.', 'Regardez-moi !'],\n",
       " ['Watch us.', 'Regardez-nous !'],\n",
       " ['Watch us.', 'Regarde-nous !'],\n",
       " ['We agree.', \"Nous sommes d'accord.\"],\n",
       " [\"We'll go.\", 'Nous irons.'],\n",
       " [\"We're OK.\", 'Nous allons bien.'],\n",
       " ['What for?', 'Pour quoi faireâ€¯?'],\n",
       " ['What for?', 'Ã€ quoi bon ?'],\n",
       " ['What fun!', \"Qu'est-ce qu'on s'est marrÃ©s !\"],\n",
       " ['What fun!', \"Qu'est-ce qu'on s'est marrÃ©es !\"],\n",
       " ['Who am I?', 'Qui suis-je ?'],\n",
       " ['Who came?', 'Qui est venu ?'],\n",
       " ['Who died?', 'Qui est mort ?'],\n",
       " ['Who fell?', 'Qui est tombÃ©Â\\xa0?'],\n",
       " ['Who lost?', 'Qui a perdu ?'],\n",
       " ['Who paid?', 'Qui a payÃ©Â\\xa0?'],\n",
       " ['Who quit?', 'Qui dÃ©missionneÂ\\xa0?'],\n",
       " [\"Who's he?\", 'Qui est-ilâ€¯?'],\n",
       " ['Write me.', 'Ã‰cris-moi !'],\n",
       " ['Write me.', 'Ã‰crivez-moi !'],\n",
       " ['You lost.', 'Tu as perdu.'],\n",
       " ['You lost.', 'Vous avez perdu.'],\n",
       " ['You lost.', 'Tâ€™as perdu.'],\n",
       " ['After you.', 'Je vous en prie.'],\n",
       " ['After you.', 'AprÃ¨s vous.'],\n",
       " ['Aim. Fire!', 'En joue ! Feu !'],\n",
       " ['Am I late?', 'Suis-je en retard ?'],\n",
       " ['Answer me.', 'RÃ©pondez-moi.'],\n",
       " ['Be honest.', 'Sois honnÃªte.'],\n",
       " ['Be honest.', 'Soyez honnÃªtes.'],\n",
       " ['Be honest.', 'Soyez honnÃªte.'],\n",
       " ['Be seated.', 'Assieds-toi !'],\n",
       " ['Be seated.', 'Asseyez-vous !'],\n",
       " ['Be seated.', 'Asseyez-vous.'],\n",
       " ['Be strong.', 'Sois puissanteÂ\\xa0!'],\n",
       " ['Birds fly.', 'Les oiseaux volent.'],\n",
       " ['Bless you.', 'Ã€ tes souhaitsâ€¯!'],\n",
       " ['Call home!', 'Appelle Ã\\xa0 la maison !'],\n",
       " ['Calm down!', 'Calmez-vous !'],\n",
       " ['Calm down!', 'Du calme.'],\n",
       " ['Calm down!', 'Tranquille.'],\n",
       " ['Calm down.', 'Calme-toi.'],\n",
       " ['Calm down.', 'Du calme.'],\n",
       " ['Calm down.', 'Tranquille.'],\n",
       " ['Can we go?', 'Pouvons-nous partir ?'],\n",
       " ['Can we go?', 'Pouvons-nous nous en aller ?'],\n",
       " ['Can we go?', 'Pouvons-nous y aller ?'],\n",
       " ['Catch Tom.', 'Attrape Tom.'],\n",
       " ['Catch Tom.', 'Attrapez Tom.'],\n",
       " ['Catch him.', 'Attrape-leâ€¯!'],\n",
       " ['Catch him.', 'Rattrape-le.'],\n",
       " ['Chill out.', 'Calme-toi.'],\n",
       " ['Chill out.', 'Tranquille.'],\n",
       " ['Choose me.', 'Choisis-moi !'],\n",
       " ['Come back.', 'Reviens !'],\n",
       " ['Come back.', 'Revenez !'],\n",
       " ['Come here.', 'Viens ici.'],\n",
       " ['Come here.', 'Venez lÃ\\xa0.'],\n",
       " ['Come over.', 'Venez ici !'],\n",
       " ['Come over.', 'Viens chez nous !'],\n",
       " ['Come over.', 'Venez chez nous !'],\n",
       " ['Come over.', 'Viens chez moi !'],\n",
       " ['Come over.', 'Venez chez moi !'],\n",
       " ['Come soon.', 'Viens bientÃ´t !'],\n",
       " ['Come soon.', 'Venez bientÃ´t !'],\n",
       " ['Cool down.', 'Calmez-vous !'],\n",
       " ['Did I win?', 'Ai-je gagnÃ© ?'],\n",
       " ['Did I win?', \"L'ai-je emportÃ© ?\"],\n",
       " ['Did I win?', 'Est-ce moi qui ai gagnÃ© ?'],\n",
       " ['Do it now.', 'Faites-le maintenant.'],\n",
       " ['Dogs bark.', 'Des chiens aboient.'],\n",
       " ['Dogs bark.', 'Les chiens aboient.'],\n",
       " [\"Don't ask.\", 'Ne demande pas !'],\n",
       " [\"Don't cry.\", 'Ne pleure pas !'],\n",
       " [\"Don't die.\", 'Ne meurs pas !'],\n",
       " [\"Don't die.\", 'Ne mourez pas !'],\n",
       " [\"Don't lie.\", 'Ne mens pas.'],\n",
       " [\"Don't lie.\", 'Ne mens pas !'],\n",
       " [\"Don't run.\", 'Ne courez pas.'],\n",
       " [\"Don't run.\", 'Ne cours pas.'],\n",
       " ['Excuse me.', 'Excuse-moi.'],\n",
       " ['Excuse me.', 'Excusez-moi.'],\n",
       " ['Excuse me?', 'Pardonâ€¯?'],\n",
       " ['Excuse me?', 'Je vous demande pardonâ€¯?'],\n",
       " ['Excuse me?', 'PlaÃ®t-ilâ€¯?'],\n",
       " ['Excuse me?', 'Plait-ilâ€¯?'],\n",
       " ['Excuse me?', 'Pardon ?'],\n",
       " ['Fantastic!', 'Fantastiqueâ€¯!'],\n",
       " ['Fantastic!', 'FantastiqueÂ\\xa0!'],\n",
       " ['Fantastic!', 'Sensass !'],\n",
       " ['Feel this.', 'Sens Ã§a !'],\n",
       " ['Feel this.', 'Sentez Ã§a !'],\n",
       " ['Feel this.', 'Touche Ã§a !'],\n",
       " ['Feel this.', 'Touchez Ã§a !'],\n",
       " ['Film this.', 'Filmez ceci.'],\n",
       " ['Film this.', 'Filme ceci.'],\n",
       " ['Follow me.', 'Suis-moi.'],\n",
       " ['Follow us.', 'Suis-nous !'],\n",
       " ['Follow us.', 'Suivez-nous !'],\n",
       " ['Forget it!', 'Oublie !'],\n",
       " ['Forget it!', 'Oublie-le !'],\n",
       " ['Forget it!', 'Oubliez !'],\n",
       " ['Forget it!', 'Oubliez-le !'],\n",
       " ['Forget it!', 'Laissez tomber.'],\n",
       " ['Forget it!', 'Oubliez Ã§a !'],\n",
       " ['Forget it.', 'Laisse tomber.'],\n",
       " ['Forget it.', 'Oublie.'],\n",
       " ['Forget it.', 'Oublie-le !'],\n",
       " ['Forget it.', 'Laissez tomber.'],\n",
       " ['Forget it.', 'Oubliez Ã§a !'],\n",
       " ['Forget me.', 'Oublie-moi.'],\n",
       " ['Forget me.', 'Oubliez-moi.'],\n",
       " ['Get a job.', 'Trouve un emploi !'],\n",
       " ['Get a job.', 'Trouve un boulot !'],\n",
       " ['Get a job.', 'Trouvez un emploi !'],\n",
       " ['Get a job.', 'Trouvez un boulot !'],\n",
       " ['Get going.', 'Vas-y.'],\n",
       " ['Get going.', 'Allez-y.'],\n",
       " ['Get going.', 'Marche.'],\n",
       " ['Get going.', 'Avance.'],\n",
       " ['Get going.', 'En avant.'],\n",
       " ['Get going.', 'DÃ©place-toi.'],\n",
       " ['Get going.', 'DÃ©placez-vous.'],\n",
       " ['Get going.', 'En route.'],\n",
       " ['Get ready.', 'PrÃ©pare-toi.'],\n",
       " ['Get ready.', 'PrÃ©parez-vous.'],\n",
       " ['Go faster.', 'Va plus vite.'],\n",
       " ['Go faster.', 'Allez plus vite.'],\n",
       " ['Go get it.', 'Va le chercher !'],\n",
       " ['Go get it.', 'Allez le chercher !'],\n",
       " ['Go inside.', 'Entrezâ€¯!'],\n",
       " ['Go to bed.', 'Va dormirâ€¯!'],\n",
       " ['Go to bed.', 'Va au lit !'],\n",
       " ['Go to bed.', 'Au lit !'],\n",
       " ['Go to bed.', 'Allez au lit !'],\n",
       " ['Go to bed.', 'File au lit !'],\n",
       " ['Go to bed.', 'Au dodo !'],\n",
       " ['Go to bed.', 'Va te coucher !'],\n",
       " ['Good luck.', 'Bonne chanceâ€¯!'],\n",
       " ['Good luck.', 'Bonne chance.'],\n",
       " ['Good luck.', 'Bonne continuation !'],\n",
       " ['Grab that.', 'Attrape Ã§a !'],\n",
       " ['Grab that.', 'Attrapez Ã§a !'],\n",
       " ['Grab that.', 'Saisis-toi de Ã§a !'],\n",
       " ['Grab that.', 'Saisissez-vous de Ã§a !'],\n",
       " ['Grab this.', 'Attrape Ã§a !'],\n",
       " ['Grab this.', 'Attrapez Ã§a !'],\n",
       " ['Hands off.', 'Pas toucheâ€¯!'],\n",
       " ['Hands off.', 'Ne touche pas Ã\\xa0 Ã§a !'],\n",
       " ['Have some.', 'Prenez-en.'],\n",
       " ['Have some.', 'Prends-en.'],\n",
       " ['He is ill.', 'Il est malade.'],\n",
       " ['He is old.', 'Il est vieux.'],\n",
       " [\"He's a DJ.\", 'Il est DJ.'],\n",
       " [\"He's good.\", 'Il est bon.'],\n",
       " [\"He's lazy.\", 'Il est paresseux.'],\n",
       " [\"He's mine.\", 'Il est Ã\\xa0 moi.'],\n",
       " [\"He's rich.\", 'Il est riche.'],\n",
       " [\"He's sexy.\", 'Il est sexy.'],\n",
       " ['Head east.', \"Dirigez-vous vers l'est.\"],\n",
       " ['Head east.', \"Dirige-toi vers l'est.\"],\n",
       " ['Head west.', \"Dirigez-vous vers l'ouest.\"],\n",
       " ['Head west.', \"Dirige-toi vers l'ouest.\"],\n",
       " ['Here I am.', 'Me voici.'],\n",
       " [\"Here's $5.\", 'VoilÃ\\xa0 cinq dollars.'],\n",
       " ['Hold fire.', 'Halte au feu !'],\n",
       " ['Hold fire.', 'Cessez le feu !'],\n",
       " ['Hold this.', 'Tenez.'],\n",
       " ['Hold this.', 'Tiens Ã§a !'],\n",
       " ['Hold this.', 'Tenez Ã§a !'],\n",
       " ['Hold this.', 'Tenez ceci !'],\n",
       " ['Hold this.', 'Tiens ceci !'],\n",
       " ['How awful!', \"C'est affreuxâ€¯!\"],\n",
       " ['How awful!', \"C'est horrible !\"],\n",
       " ['How weird!', \"Comme c'est bizarre !\"],\n",
       " [\"How's Tom?\", 'Comment Tom va-t-il ?'],\n",
       " [\"How's Tom?\", 'Comment va Tom ?'],\n",
       " ['Humor Tom.', 'Mettez Tom de bonne humeur.'],\n",
       " ['Humor Tom.', 'Mets Tom de bonne humeur.'],\n",
       " ['I am cold.', \"J'ai froid.\"],\n",
       " ['I am good.', 'Je suis bon.'],\n",
       " ['I am here.', 'Je suis ici.'],\n",
       " ['I am okay.', 'Je vais bien.'],\n",
       " ['I am sick.', 'Je suis malade.'],\n",
       " ['I am sure.', 'Je suis sÃ»r.'],\n",
       " ['I am sure.', 'Je suis certain.'],\n",
       " ...]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jnmGqtDOqdKN"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "def sentencetoIndexes(sentence, lang):\n",
    "    indexes = [lang.word2int[word] for word in sentence.split()]\n",
    "    indexes.append(EOS_token)\n",
    "    return indexes\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split()) < MAX_LENGTH and len(p[1].split()) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "pairs = filterPairs(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GQbB37mcsHb_",
    "outputId": "fad2916c-973b-49e3-9543-ca0dbefa43ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.', 'Va !']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JlAGPZShqdKT"
   },
   "outputs": [],
   "source": [
    "def build_lang(lang1, lang2, max_length=10):\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "    input_seq = []\n",
    "    output_seq = []\n",
    "    \n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[1])\n",
    "        output_lang.addSentence(pair[0])\n",
    "    for pair in pairs:\n",
    "        input_seq.append(sentencetoIndexes(pair[1], input_lang))\n",
    "        output_seq.append(sentencetoIndexes(pair[0], output_lang))\n",
    "    return keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=max_length, padding='post',\n",
    "                                                      truncating='post'), \\\n",
    "keras.preprocessing.sequence.pad_sequences(output_seq, padding='post', truncating='post'), input_lang, output_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9MAxjU-qdKY"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Ã'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9516/2878808059.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_lang\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_lang\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9516/495379872.py\u001b[0m in \u001b[0;36mbuild_lang\u001b[1;34m(lang1, lang2, max_length)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0moutput_lang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0minput_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentencetoIndexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0moutput_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentencetoIndexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     return keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=max_length, padding='post',\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9516/1227622703.py\u001b[0m in \u001b[0;36msentencetoIndexes\u001b[1;34m(sentence, lang)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msentencetoIndexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mindexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2int\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEOS_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9516/1227622703.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msentencetoIndexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mindexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2int\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEOS_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Ã'"
     ]
    }
   ],
   "source": [
    "input_tensor, output_tensor, input_lang, output_lang = build_lang('fr', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Lang at 0x22533c23d00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YZ8Pcm1Ls8Cc",
    "outputId": "2937839a-ccbd-4eba-da49-85f03e91bdbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fr'"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qii6d6iKqdKc"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = len(input_tensor)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor, output_tensor)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41nSXuflqdKh"
   },
   "outputs": [],
   "source": [
    "class Encoder(keras.models.Model):\n",
    "    def __init__(self, vocab_size, num_hidden=256, num_embedding=256, batch_size=16):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_embedding = num_embedding\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, num_embedding)\n",
    "        self.gru = keras.layers.GRU(num_hidden, return_sequences=True,\n",
    "                                    recurrent_initializer='glorot_uniform',\n",
    "                                   return_state=True)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        rnn_out, hidden = self.gru(embedded, initial_state=hidden)\n",
    "        return rnn_out, hidden\n",
    "    def init_hidden(self):\n",
    "        return tf.zeros(shape=(self.batch_size, self.num_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qm8zLgoqdKk"
   },
   "outputs": [],
   "source": [
    "inputs, outputs = next(iter(dataset))\n",
    "hidden = tf.zeros((16, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5AHvxMiqdKo"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(input_lang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bCF-S8fBqdKs"
   },
   "outputs": [],
   "source": [
    "e_outputs, e_hidden = encoder(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "AqGefguVqdKv",
    "outputId": "0b8b976b-6267-40b2-be27-f663781cf1f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 256), dtype=float32, numpy=\n",
       "array([[-0.01316416, -0.01187541,  0.03886399, ..., -0.02306043,\n",
       "         0.0013533 , -0.01424476],\n",
       "       [-0.01347641, -0.01399617,  0.04546529, ..., -0.02501968,\n",
       "         0.00277372, -0.01384097],\n",
       "       [-0.01612211, -0.00936785,  0.03525378, ..., -0.01767884,\n",
       "         0.0026657 , -0.01332709],\n",
       "       ...,\n",
       "       [-0.01279999, -0.01188518,  0.04017877, ..., -0.01974327,\n",
       "         0.00475456, -0.01134078],\n",
       "       [-0.01489186, -0.01252952,  0.04177019, ..., -0.02204917,\n",
       "         0.00012073, -0.01244862],\n",
       "       [-0.01376239, -0.01104986,  0.04156855, ..., -0.02214067,\n",
       "         0.00313638, -0.0132139 ]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_bJHJsq1qdK6"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(keras.models.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "    \n",
    "        self.W1 = keras.layers.Dense(units)\n",
    "        self.W2 = keras.layers.Dense(units)\n",
    "        self.V = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, encoder_out, hidden):\n",
    "        #shape of encoder_out : batch_size, seq_length, hidden_dim \n",
    "        #shape of encoder_hidden : batch_size, hidden_dim \n",
    "        \n",
    "        hidden = tf.expand_dims(hidden, axis=1) #out:\n",
    "        \n",
    "        score = self.V(tf.nn.tanh(self.W1(encoder_out) + \\\n",
    "                                  self.W2(hidden))) \n",
    "        \n",
    "        attn_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        context =  attn_weights * encoder_out \n",
    "        context = tf.reduce_sum(context, axis=1)\n",
    "        return context, attn_weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gRC60cCqdK-"
   },
   "outputs": [],
   "source": [
    "attn = BahdanauAttention(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHU6rIRzqdLC"
   },
   "outputs": [],
   "source": [
    "context, attn_weights = attn(e_outputs, e_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G2XacZYkqdLK",
    "outputId": "2f5997bb-f3bd-4679-e12a-70f2181bfbe6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 10, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsLImrCwqdLT"
   },
   "outputs": [],
   "source": [
    "class Decoder(keras.models.Model):\n",
    "    def __init__(self, vocab_size, dec_dim=256, embedding_dim=256):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.attn = BahdanauAttention(dec_dim)\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = keras.layers.GRU(dec_dim, recurrent_initializer='glorot_uniform',\n",
    "                                   return_sequences=True, return_state=True)\n",
    "        self.fc = keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x, enc_hidden, enc_out):\n",
    "        x = self.embedding(x)\n",
    "        context, attn_weights = self.attn(enc_out, enc_hidden)\n",
    "        x = tf.concat((tf.expand_dims(context, 1), x), -1)\n",
    "        r_out, hidden = self.gru(x, initial_state=enc_hidden)\n",
    "        out = tf.reshape(r_out,shape=(-1, r_out.shape[2]))\n",
    "        return self.fc(out), hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ItYHAqWJqdLY"
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(output_lang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XnhNtfb9qdLe"
   },
   "outputs": [],
   "source": [
    "input_tensor, output_tensor = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7Y7QsykqdLi"
   },
   "outputs": [],
   "source": [
    "x = np.expand_dims(output_tensor[:,1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DE7fnvAqdLp"
   },
   "outputs": [],
   "source": [
    "def loss_fn(real, pred):\n",
    "    criterion = keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                           reduction='none')\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    _loss = criterion(real, pred)\n",
    "    mask = tf.cast(mask, dtype=_loss.dtype)\n",
    "    _loss *= mask\n",
    "    return tf.reduce_mean(_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMc7zD6WqdLt"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hiAmynEsqdLw"
   },
   "outputs": [],
   "source": [
    "def train_step(input_tensor, target_tensor, enc_hidden):\n",
    "    loss = 0.0\n",
    "    with tf.GradientTape() as tape:\n",
    "    \n",
    "        batch_size = input_tensor.shape[0]\n",
    "        enc_output, enc_hidden = encoder(input_tensor, enc_hidden)\n",
    "\n",
    "        SOS_tensor = np.array([SOS_token])\n",
    "        dec_input = tf.squeeze(tf.expand_dims([SOS_tensor]*batch_size, 1), -1)\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        for tx in range(target_tensor.shape[1]-1):\n",
    "          \n",
    "            dec_out, dec_hidden, _ = decoder(dec_input, dec_hidden,\n",
    "                                            enc_output)\n",
    "            loss += loss_fn(target_tensor[:, tx], dec_out)\n",
    "            dec_input = tf.expand_dims(target_tensor[:, tx], 1)\n",
    "\n",
    "    batch_loss = loss / target_tensor.shape[1]\n",
    "    t_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, t_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, t_variables))\n",
    "    return batch_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6kj6diJMqdL0",
    "outputId": "97f30803-0152-4e1a-dee9-92d68251ec4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(7.0363297, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "hidden = tf.zeros(shape=(16, 256))\n",
    "loss = train_step(input_tensor, output_tensor, hidden)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lk_OG391qdL5"
   },
   "outputs": [],
   "source": [
    "def checkpoint(model, name=None):\n",
    "    if name is not None:\n",
    "        model.save_weights('/content/gdrive/My Drive/{}.h5'.format(name))\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZEbkwx9qdL-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 batch_loss: 6.7956\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = '/content/gdrive/My Drive/encoder.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9516/2974502890.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mloss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epochs: {} batch_loss: {:.4f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mcheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoder'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mcheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'decoder'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9516/939279673.py\u001b[0m in \u001b[0;36mcheckpoint\u001b[1;34m(model, name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive/My Drive/{}.h5'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python\\Anaconda\\Tensorflow Object Detection\\TFODCourse\\tfod\\lib\\site-packages\\keras-2.6.0-py3.8.egg\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave_weights\u001b[1;34m(self, filepath, overwrite, save_format, options)\u001b[0m\n\u001b[0;32m   2249\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2250\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'h5'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2251\u001b[1;33m       \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2252\u001b[0m         \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2253\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python\\Anaconda\\Tensorflow Object Detection\\TFODCourse\\tfod\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[0;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[0;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n",
      "\u001b[1;32m~\\Documents\\Python\\Anaconda\\Tensorflow Object Detection\\TFODCourse\\tfod\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to open file: name = '/content/gdrive/My Drive/encoder.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "log_every = 50\n",
    "steps_per_epoch = len(pairs) // BATCH_SIZE\n",
    "loss_list = []\n",
    "\n",
    "for e in range(1, EPOCHS):\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    enc_hidden = encoder.init_hidden()\n",
    "    \n",
    "    for idx, (input_tensor, target_tensor) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(input_tensor, target_tensor, hidden)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        if idx % log_every == 0:\n",
    "            loss_list.append(batch_loss)\n",
    "            print(\"Epochs: {} batch_loss: {:.4f}\".format(e, batch_loss))\n",
    "            checkpoint(encoder, 'encoder')\n",
    "            checkpoint(decoder, 'decoder')\n",
    "            \n",
    "    if e % 2 == 0:\n",
    "        print(\"Epochs: {}/{} total_loss: {:.4f}\".format(\n",
    "        e, EPOCHS, total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JuswAWMYqdME"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, max_length=10):\n",
    "    result = ''\n",
    "    attention_plot = np.zeros((10,10))\n",
    "    sentence = normalizeString(sentence)\n",
    "    sentence = sentencetoIndexes(sentence, input_lang)\n",
    "    sentence = keras.preprocessing.sequence.pad_sequences([sentence],padding='post',\n",
    "                                                      maxlen=max_length, truncating='post')\n",
    "    \n",
    "    encoder_hidden = hidden = [tf.zeros((1, 256))]\n",
    "    \n",
    "    enc_out, enc_hidden = encoder(sentence, encoder_hidden)\n",
    "    \n",
    "    dec_hidden = enc_hidden\n",
    "    SOS_tensor = np.array([SOS_token])\n",
    "    dec_input = tf.squeeze(tf.expand_dims([SOS_tensor], 1), -1)\n",
    "    \n",
    "    for tx in range(max_length):\n",
    "        dec_out, dec_hidden, attn_weights = decoder(dec_input,\n",
    "                                                   dec_hidden, enc_out)\n",
    "        attn_weights = tf.reshape(attn_weights, (-1, ))\n",
    "        attention_plot[tx] = attn_weights.numpy()\n",
    "        pred = tf.argmax(dec_out, axis=1).numpy()\n",
    "        result += output_lang.int2word[pred[0]] + \" \"\n",
    "        if output_lang.int2word[pred[0]] == \"EOS\":\n",
    "            break\n",
    "        dec_input = tf.expand_dims(pred, axis=1)\n",
    "    return result, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r7mmzYUIqdMI",
    "outputId": "e78bcf6c-9cea-4d8a-880a-27a4acabc95e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i need somebody to help me ? EOS \n"
     ]
    }
   ],
   "source": [
    "sentence = \"j'ai besoin de quelqu'un pour m'aider ?\"\n",
    "pred, attn_weights = translate(sentence)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-s9cnSvUxNIC"
   },
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    sentence = normalizeString(sentence)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpf4T5z_3JP4"
   },
   "outputs": [],
   "source": [
    "from matplotlib import ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "5A9xpAf6xsgL",
    "outputId": "fa47f721-b6e9-4a46-84e2-e402738e7bdc"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-87d681c8761a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-96-e2eb4a2889fa>\u001b[0m in \u001b[0;36mplot_attention\u001b[0;34m(attention, sentence, predicted_sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizeString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'viridis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7fa98ec041b7>\u001b[0m in \u001b[0;36mnormalizeString\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalizeString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0municodeToAscii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"([!.?])\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr\" \\1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"[^a-zA-Z?.!]+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "attn_weights = attn_weights[:len(pred.split(' ')), :len(sentence.split(' '))]\n",
    "plot_attention(attn_weights, sentence.split(), pred.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yROfA7newSua"
   },
   "outputs": [],
   "source": [
    "encoder.load_weights('/content/gdrive/My Drive/encoder.h5')\n",
    "decoder.load_weights('/content/gdrive/My Drive/decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vDXB800z9GC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "machine translation tensorflow orig.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
