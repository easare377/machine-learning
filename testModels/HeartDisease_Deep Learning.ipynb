{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# keras imports for the dataset and building our neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'data'\n",
    "HEART_CSV = os.path.join(DATA_PATH, 'heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "heart_df = pd.read_csv(HEART_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>TA</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132</td>\n",
       "      <td>N</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>141</td>\n",
       "      <td>N</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>115</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>LVH</td>\n",
       "      <td>174</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>38</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>173</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n",
       "0     40   M           ATA        140          289          0     Normal   \n",
       "1     49   F           NAP        160          180          0     Normal   \n",
       "2     37   M           ATA        130          283          0         ST   \n",
       "3     48   F           ASY        138          214          0     Normal   \n",
       "4     54   M           NAP        150          195          0     Normal   \n",
       "..   ...  ..           ...        ...          ...        ...        ...   \n",
       "913   45   M            TA        110          264          0     Normal   \n",
       "914   68   M           ASY        144          193          1     Normal   \n",
       "915   57   M           ASY        130          131          0     Normal   \n",
       "916   57   F           ATA        130          236          0        LVH   \n",
       "917   38   M           NAP        138          175          0     Normal   \n",
       "\n",
       "     MaxHR ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0      172              N      0.0       Up             0  \n",
       "1      156              N      1.0     Flat             1  \n",
       "2       98              N      0.0       Up             0  \n",
       "3      108              Y      1.5     Flat             1  \n",
       "4      122              N      0.0       Up             0  \n",
       "..     ...            ...      ...      ...           ...  \n",
       "913    132              N      1.2     Flat             1  \n",
       "914    141              N      3.4     Flat             1  \n",
       "915    115              Y      1.2     Flat             1  \n",
       "916    174              N      0.0     Flat             1  \n",
       "917    173              N      0.0       Up             0  \n",
       "\n",
       "[918 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from category_encoder import CategoryEncoder\n",
    "enc = CategoryEncoder(data_frame=heart_df, columns=['Sex','ChestPainType','RestingECG', 'ExerciseAngina', 'ST_Slope'])\n",
    "heart_df = enc.get_encoded_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>TA</th>\n",
       "      <th>...</th>\n",
       "      <th>ASY</th>\n",
       "      <th>ATA</th>\n",
       "      <th>LVH</th>\n",
       "      <th>ST</th>\n",
       "      <th>Normal</th>\n",
       "      <th>N</th>\n",
       "      <th>Y</th>\n",
       "      <th>Flat</th>\n",
       "      <th>Up</th>\n",
       "      <th>Down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>45</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>68</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>57</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>57</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>38</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  HeartDisease  F  \\\n",
       "0     40        140          289          0    172      0.0             0  0   \n",
       "1     49        160          180          0    156      1.0             1  1   \n",
       "2     37        130          283          0     98      0.0             0  0   \n",
       "3     48        138          214          0    108      1.5             1  1   \n",
       "4     54        150          195          0    122      0.0             0  0   \n",
       "..   ...        ...          ...        ...    ...      ...           ... ..   \n",
       "913   45        110          264          0    132      1.2             1  0   \n",
       "914   68        144          193          1    141      3.4             1  0   \n",
       "915   57        130          131          0    115      1.2             1  0   \n",
       "916   57        130          236          0    174      0.0             1  1   \n",
       "917   38        138          175          0    173      0.0             0  0   \n",
       "\n",
       "     M  TA  ...  ASY  ATA  LVH  ST  Normal  N  Y  Flat  Up  Down  \n",
       "0    1   0  ...    0    1    0   0       1  1  0     0   1     0  \n",
       "1    0   0  ...    0    0    0   0       1  1  0     1   0     0  \n",
       "2    1   0  ...    0    1    0   1       0  1  0     0   1     0  \n",
       "3    0   0  ...    1    0    0   0       1  0  1     1   0     0  \n",
       "4    1   0  ...    0    0    0   0       1  1  0     0   1     0  \n",
       "..  ..  ..  ...  ...  ...  ...  ..     ... .. ..   ...  ..   ...  \n",
       "913  1   1  ...    0    0    0   0       1  1  0     1   0     0  \n",
       "914  1   0  ...    1    0    0   0       1  1  0     1   0     0  \n",
       "915  1   0  ...    1    0    0   0       1  0  1     1   0     0  \n",
       "916  0   0  ...    0    1    1   0       0  1  0     1   0     0  \n",
       "917  1   0  ...    0    0    0   0       1  1  0     0   1     0  \n",
       "\n",
       "[918 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458\n"
     ]
    }
   ],
   "source": [
    "print(len(heart_df[(heart_df.Sex == 'M') & (heart_df.HeartDisease == 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Males:  725\n",
      "Females:  193\n"
     ]
    }
   ],
   "source": [
    "print('Males: ', len(heart_df[(heart_df.Sex == 'M')]))\n",
    "print('Females: ', len(heart_df[(heart_df.Sex == 'F')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heart_df[(heart_df.Sex == 'M') & (heart_df.HeartDisease == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heart_df[(heart_df.Sex == 'F') & (heart_df.HeartDisease == 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize % of males and females who have heart diseases\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['C', 'C++', 'Java', 'Python', 'PHP']\n",
    "gender = ['Male', 'Female']\n",
    "malePer =  len(heart_df[(heart_df.Sex == 'M') & (heart_df.HeartDisease == 1)]) / len(heart_df[(heart_df.Sex == 'M')])\n",
    "malePer *= 100\n",
    "femalePer =  len(heart_df[(heart_df.Sex == 'F') & (heart_df.HeartDisease == 1)]) / len(heart_df[(heart_df.Sex == 'F')])\n",
    "femalePer *= 100\n",
    "heart_disease = [malePer, femalePer]\n",
    "students = [23,17,35,29,12]\n",
    "ax.bar(gender,heart_disease)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizer RestingECG\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "gender = ['Normal', 'LVH', 'ST']\n",
    "normalPer =  len(heart_df[(heart_df.RestingECG == 'Normal') & (heart_df.HeartDisease == 1)]) / len(heart_df[(heart_df.RestingECG == 'Normal')]) * 100\n",
    "lvhPer =  len(heart_df[(heart_df.RestingECG == 'LVH') & (heart_df.HeartDisease == 1)]) / len(heart_df[(heart_df.RestingECG == 'LVH')]) * 100\n",
    "stPer = len(heart_df[(heart_df.RestingECG == 'ST') & (heart_df.HeartDisease == 1)]) / len(heart_df[(heart_df.RestingECG == 'ST')]) * 100\n",
    "heart_disease = [normalPer, lvhPer, stPer]\n",
    "ax.bar(gender,heart_disease)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizer RestingECG\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "gender = ['Normal', 'LVH', 'ST']\n",
    "normalPer =  len(heart_df[(heart_df.RestingECG == 'Normal') & (heart_df.HeartDisease == 1)]) / len(heart_df[(heart_df.RestingECG == 'Normal')]) * 100\n",
    "lvhPer =  len(heart_df[(heart_df.RestingECG == 'LVH') & (heart_df.HeartDisease == 1)]) / len(heart_df[(heart_df.RestingECG == 'LVH')]) * 100\n",
    "stPer = len(heart_df[(heart_df.RestingECG == 'ST') & (heart_df.HeartDisease == 1)]) / len(heart_df[(heart_df.RestingECG == 'ST')]) * 100\n",
    "heart_disease = [normalPer, lvhPer, stPer]\n",
    "ax.bar(gender,heart_disease)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize ExerciseAngina\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "exerciseAngina = ['Yes', 'No']\n",
    "yesPer =  len(heart_df[(heart_df.ExerciseAngina == 'Y') & (heart_df.HeartDisease == 1)]) / len(heart_df[(heart_df.ExerciseAngina == 'Y')]) * 100\n",
    "noPer = len(heart_df[(heart_df.ExerciseAngina == 'N') & (heart_df.HeartDisease == 1)]) / len(heart_df[(heart_df.ExerciseAngina == 'N')]) * 100\n",
    "heart_disease = [yesPer, noPer]\n",
    "ax.bar(exerciseAngina,heart_disease)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize ST_Slope\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "st_Slope = ['Up', 'Flat']\n",
    "upPer =  len(heart_df[(heart_df.ST_Slope == 'Up') & (heart_df.HeartDisease == 1)]) / len(heart_df[(heart_df.ST_Slope == 'Up')]) * 100\n",
    "flatPer = len(heart_df[(heart_df.ST_Slope == 'Flat') & (heart_df.HeartDisease == 1)]) / len(heart_df[(heart_df.ST_Slope == 'Flat')]) * 100\n",
    "heart_disease = [upPer, flatPer]\n",
    "ax.bar(st_Slope,heart_disease)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>TA</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132</td>\n",
       "      <td>N</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>141</td>\n",
       "      <td>N</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>115</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>LVH</td>\n",
       "      <td>174</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>38</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>173</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n",
       "0     40   M           ATA        140          289          0     Normal   \n",
       "1     49   F           NAP        160          180          0     Normal   \n",
       "2     37   M           ATA        130          283          0         ST   \n",
       "3     48   F           ASY        138          214          0     Normal   \n",
       "4     54   M           NAP        150          195          0     Normal   \n",
       "..   ...  ..           ...        ...          ...        ...        ...   \n",
       "913   45   M            TA        110          264          0     Normal   \n",
       "914   68   M           ASY        144          193          1     Normal   \n",
       "915   57   M           ASY        130          131          0     Normal   \n",
       "916   57   F           ATA        130          236          0        LVH   \n",
       "917   38   M           NAP        138          175          0     Normal   \n",
       "\n",
       "     MaxHR ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0      172              N      0.0       Up             0  \n",
       "1      156              N      1.0     Flat             1  \n",
       "2       98              N      0.0       Up             0  \n",
       "3      108              Y      1.5     Flat             1  \n",
       "4      122              N      0.0       Up             0  \n",
       "..     ...            ...      ...      ...           ...  \n",
       "913    132              N      1.2     Flat             1  \n",
       "914    141              N      3.4     Flat             1  \n",
       "915    115              Y      1.2     Flat             1  \n",
       "916    174              N      0.0     Flat             1  \n",
       "917    173              N      0.0       Up             0  \n",
       "\n",
       "[918 rows x 12 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = heart_df.drop('HeartDisease', axis=1)\n",
    "Y = heart_df['HeartDisease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>TA</th>\n",
       "      <th>NAP</th>\n",
       "      <th>ATA</th>\n",
       "      <th>ASY</th>\n",
       "      <th>Normal</th>\n",
       "      <th>ST</th>\n",
       "      <th>LVH</th>\n",
       "      <th>Y</th>\n",
       "      <th>N</th>\n",
       "      <th>Flat</th>\n",
       "      <th>Down</th>\n",
       "      <th>Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>45</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>68</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>57</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>57</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>38</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  F  M  TA  NAP  \\\n",
       "0     40        140          289          0    172      0.0  0  1   0    0   \n",
       "1     49        160          180          0    156      1.0  1  0   0    1   \n",
       "2     37        130          283          0     98      0.0  0  1   0    0   \n",
       "3     48        138          214          0    108      1.5  1  0   0    0   \n",
       "4     54        150          195          0    122      0.0  0  1   0    1   \n",
       "..   ...        ...          ...        ...    ...      ... .. ..  ..  ...   \n",
       "913   45        110          264          0    132      1.2  0  1   1    0   \n",
       "914   68        144          193          1    141      3.4  0  1   0    0   \n",
       "915   57        130          131          0    115      1.2  0  1   0    0   \n",
       "916   57        130          236          0    174      0.0  1  0   0    0   \n",
       "917   38        138          175          0    173      0.0  0  1   0    1   \n",
       "\n",
       "     ATA  ASY  Normal  ST  LVH  Y  N  Flat  Down  Up  \n",
       "0      1    0       1   0    0  0  1     0     0   1  \n",
       "1      0    0       1   0    0  0  1     1     0   0  \n",
       "2      1    0       0   1    0  0  1     0     0   1  \n",
       "3      0    1       1   0    0  1  0     1     0   0  \n",
       "4      0    0       1   0    0  0  1     0     0   1  \n",
       "..   ...  ...     ...  ..  ... .. ..   ...   ...  ..  \n",
       "913    0    0       1   0    0  0  1     1     0   0  \n",
       "914    0    1       1   0    0  0  1     1     0   0  \n",
       "915    0    1       1   0    0  1  0     1     0   0  \n",
       "916    1    0       0   0    1  0  1     1     0   0  \n",
       "917    0    0       1   0    0  0  1     0     0   1  \n",
       "\n",
       "[918 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "913    1\n",
       "914    1\n",
       "915    1\n",
       "916    1\n",
       "917    0\n",
       "Name: HeartDisease, Length: 918, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 'M', 'ATA', ..., 'N', 0.0, 'Up'],\n",
       "       [49, 'F', 'NAP', ..., 'N', 1.0, 'Flat'],\n",
       "       [37, 'M', 'ATA', ..., 'N', 0.0, 'Up'],\n",
       "       ...,\n",
       "       [57, 'M', 'ASY', ..., 'Y', 1.2, 'Flat'],\n",
       "       [57, 'F', 'ATA', ..., 'N', 0.0, 'Flat'],\n",
       "       [38, 'M', 'NAP', ..., 'N', 0.0, 'Up']], dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['40', 'M', 'ATA', '140', '289', '0', 'Normal', '172', 'N', '0',\n",
       "        'Up']], dtype=object)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ds = X_train.to_numpy()\n",
    "X_test_ds = X_test.to_numpy()\n",
    "Y_train_ds = Y_train.to_numpy()\n",
    "Y_test_ds = Y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ds = X_train_ds / 1000\n",
    "X_test_ds = X_test_ds / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df(train_df, test_df):\n",
    "    train = train_df.to_numpy()\n",
    "    test_ds = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (734,)\n",
      "Shape after one-hot encoding:  (734, 2)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 2\n",
    "print(\"Shape before one-hot encoding: \", Y_train_ds.shape)\n",
    "Y_train_ds = np_utils.to_categorical(Y_train_ds, n_classes)\n",
    "Y_test_ds = np_utils.to_categorical(Y_test_ds, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train_ds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train_ds = X_train.to_numpy()\n",
    "Y_train_ds = Y_train.to_numpy()\n",
    "X_train_ds = X_train_ds.reshape(734,20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 42.]\n",
      "  [120.]\n",
      "  [240.]\n",
      "  ...\n",
      "  [  0.]\n",
      "  [  1.]\n",
      "  [  0.]]\n",
      "\n",
      " [[ 36.]\n",
      "  [130.]\n",
      "  [209.]\n",
      "  ...\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  1.]]\n",
      "\n",
      " [[ 56.]\n",
      "  [150.]\n",
      "  [213.]\n",
      "  ...\n",
      "  [  1.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 60.]\n",
      "  [130.]\n",
      "  [253.]\n",
      "  ...\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  1.]]\n",
      "\n",
      " [[ 60.]\n",
      "  [152.]\n",
      "  [  0.]\n",
      "  ...\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  1.]]\n",
      "\n",
      " [[ 40.]\n",
      "  [150.]\n",
      "  [392.]\n",
      "  ...\n",
      "  [  1.]\n",
      "  [  0.]\n",
      "  [  0.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(734, 20, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_ds)\n",
    "X_train_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0\n",
      " 1 1 0 1 0 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1\n",
      " 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1\n",
      " 0 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1\n",
      " 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1\n",
      " 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1\n",
      " 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1\n",
      " 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1\n",
      " 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 0 1 0\n",
      " 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1\n",
      " 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 1\n",
      " 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(734,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y_train_ds)\n",
    "Y_train_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_ds = Y_train_ds.astype('float32').reshape((-1,1))\n",
    "Y_test_ds = Y_test_ds.astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 100)               2100      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 4,141\n",
      "Trainable params: 4,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "# hidden layer\n",
    "model.add(Dense(100, input_shape=(20,), activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "# wandb.init(project='simple-lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "6/6 [==============================] - 1s 46ms/step - loss: 0.6911 - accuracy: 0.5463 - val_loss: 0.6868 - val_accuracy: 0.5815\n",
      "Epoch 2/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6864 - accuracy: 0.5463 - val_loss: 0.6833 - val_accuracy: 0.5815\n",
      "Epoch 3/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6834 - accuracy: 0.5463 - val_loss: 0.6801 - val_accuracy: 0.5815\n",
      "Epoch 4/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6802 - accuracy: 0.5463 - val_loss: 0.6781 - val_accuracy: 0.5815\n",
      "Epoch 5/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6772 - accuracy: 0.5463 - val_loss: 0.6760 - val_accuracy: 0.5815\n",
      "Epoch 6/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6743 - accuracy: 0.5463 - val_loss: 0.6734 - val_accuracy: 0.5761\n",
      "Epoch 7/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6716 - accuracy: 0.5490 - val_loss: 0.6706 - val_accuracy: 0.5815\n",
      "Epoch 8/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6684 - accuracy: 0.5654 - val_loss: 0.6687 - val_accuracy: 0.5815\n",
      "Epoch 9/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6656 - accuracy: 0.5817 - val_loss: 0.6676 - val_accuracy: 0.5815\n",
      "Epoch 10/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6622 - accuracy: 0.6049 - val_loss: 0.6651 - val_accuracy: 0.5652\n",
      "Epoch 11/600\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6589 - accuracy: 0.6104 - val_loss: 0.6618 - val_accuracy: 0.5707\n",
      "Epoch 12/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6555 - accuracy: 0.6144 - val_loss: 0.6598 - val_accuracy: 0.5707\n",
      "Epoch 13/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6520 - accuracy: 0.6267 - val_loss: 0.6572 - val_accuracy: 0.5815\n",
      "Epoch 14/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6488 - accuracy: 0.6417 - val_loss: 0.6556 - val_accuracy: 0.5435\n",
      "Epoch 15/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6448 - accuracy: 0.6390 - val_loss: 0.6526 - val_accuracy: 0.5326\n",
      "Epoch 16/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6414 - accuracy: 0.6431 - val_loss: 0.6502 - val_accuracy: 0.5435\n",
      "Epoch 17/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6380 - accuracy: 0.6444 - val_loss: 0.6469 - val_accuracy: 0.5652\n",
      "Epoch 18/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6342 - accuracy: 0.6540 - val_loss: 0.6458 - val_accuracy: 0.5543\n",
      "Epoch 19/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6305 - accuracy: 0.6649 - val_loss: 0.6438 - val_accuracy: 0.5652\n",
      "Epoch 20/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6270 - accuracy: 0.6594 - val_loss: 0.6403 - val_accuracy: 0.5652\n",
      "Epoch 21/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6234 - accuracy: 0.6594 - val_loss: 0.6387 - val_accuracy: 0.5815\n",
      "Epoch 22/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6204 - accuracy: 0.6757 - val_loss: 0.6383 - val_accuracy: 0.5652\n",
      "Epoch 23/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6167 - accuracy: 0.6757 - val_loss: 0.6333 - val_accuracy: 0.5924\n",
      "Epoch 24/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6132 - accuracy: 0.6866 - val_loss: 0.6319 - val_accuracy: 0.5978\n",
      "Epoch 25/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6114 - accuracy: 0.6989 - val_loss: 0.6313 - val_accuracy: 0.5707\n",
      "Epoch 26/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6070 - accuracy: 0.6866 - val_loss: 0.6258 - val_accuracy: 0.6087\n",
      "Epoch 27/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6055 - accuracy: 0.6853 - val_loss: 0.6276 - val_accuracy: 0.5761\n",
      "Epoch 28/600\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5999 - accuracy: 0.7071 - val_loss: 0.6218 - val_accuracy: 0.6087\n",
      "Epoch 29/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5976 - accuracy: 0.7057 - val_loss: 0.6190 - val_accuracy: 0.6141\n",
      "Epoch 30/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5946 - accuracy: 0.7016 - val_loss: 0.6169 - val_accuracy: 0.6087\n",
      "Epoch 31/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5916 - accuracy: 0.7234 - val_loss: 0.6192 - val_accuracy: 0.6087\n",
      "Epoch 32/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5880 - accuracy: 0.7234 - val_loss: 0.6116 - val_accuracy: 0.6141\n",
      "Epoch 33/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5867 - accuracy: 0.7166 - val_loss: 0.6075 - val_accuracy: 0.6304\n",
      "Epoch 34/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5822 - accuracy: 0.7262 - val_loss: 0.6104 - val_accuracy: 0.6141\n",
      "Epoch 35/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5805 - accuracy: 0.7207 - val_loss: 0.6065 - val_accuracy: 0.6250\n",
      "Epoch 36/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5746 - accuracy: 0.7316 - val_loss: 0.6010 - val_accuracy: 0.6250\n",
      "Epoch 37/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5723 - accuracy: 0.7425 - val_loss: 0.5972 - val_accuracy: 0.6359\n",
      "Epoch 38/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5695 - accuracy: 0.7411 - val_loss: 0.5995 - val_accuracy: 0.6196\n",
      "Epoch 39/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5657 - accuracy: 0.7384 - val_loss: 0.5932 - val_accuracy: 0.6304\n",
      "Epoch 40/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5623 - accuracy: 0.7452 - val_loss: 0.5915 - val_accuracy: 0.6304\n",
      "Epoch 41/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5603 - accuracy: 0.7398 - val_loss: 0.5886 - val_accuracy: 0.6304\n",
      "Epoch 42/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5586 - accuracy: 0.7330 - val_loss: 0.5822 - val_accuracy: 0.6848\n",
      "Epoch 43/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5541 - accuracy: 0.7520 - val_loss: 0.5891 - val_accuracy: 0.6413\n",
      "Epoch 44/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5536 - accuracy: 0.7439 - val_loss: 0.5752 - val_accuracy: 0.6848\n",
      "Epoch 45/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5475 - accuracy: 0.7561 - val_loss: 0.5823 - val_accuracy: 0.6739\n",
      "Epoch 46/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5461 - accuracy: 0.7575 - val_loss: 0.5734 - val_accuracy: 0.6685\n",
      "Epoch 47/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5420 - accuracy: 0.7575 - val_loss: 0.5747 - val_accuracy: 0.6685\n",
      "Epoch 48/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5405 - accuracy: 0.7507 - val_loss: 0.5688 - val_accuracy: 0.6739\n",
      "Epoch 49/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5371 - accuracy: 0.7657 - val_loss: 0.5648 - val_accuracy: 0.6685\n",
      "Epoch 50/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5351 - accuracy: 0.7684 - val_loss: 0.5685 - val_accuracy: 0.6902\n",
      "Epoch 51/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5317 - accuracy: 0.7643 - val_loss: 0.5603 - val_accuracy: 0.6739\n",
      "Epoch 52/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5322 - accuracy: 0.7657 - val_loss: 0.5607 - val_accuracy: 0.6848\n",
      "Epoch 53/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5271 - accuracy: 0.7698 - val_loss: 0.5574 - val_accuracy: 0.6793\n",
      "Epoch 54/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.7738 - val_loss: 0.5605 - val_accuracy: 0.7011\n",
      "Epoch 55/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5276 - accuracy: 0.7589 - val_loss: 0.5515 - val_accuracy: 0.6957\n",
      "Epoch 56/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5259 - accuracy: 0.7575 - val_loss: 0.5620 - val_accuracy: 0.6957\n",
      "Epoch 57/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5183 - accuracy: 0.7738 - val_loss: 0.5467 - val_accuracy: 0.7065\n",
      "Epoch 58/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5197 - accuracy: 0.7738 - val_loss: 0.5485 - val_accuracy: 0.6848\n",
      "Epoch 59/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5172 - accuracy: 0.7711 - val_loss: 0.5508 - val_accuracy: 0.7065\n",
      "Epoch 60/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5139 - accuracy: 0.7711 - val_loss: 0.5437 - val_accuracy: 0.7011\n",
      "Epoch 61/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5143 - accuracy: 0.7779 - val_loss: 0.5449 - val_accuracy: 0.6902\n",
      "Epoch 62/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5105 - accuracy: 0.7725 - val_loss: 0.5495 - val_accuracy: 0.7174\n",
      "Epoch 63/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5103 - accuracy: 0.7752 - val_loss: 0.5400 - val_accuracy: 0.7120\n",
      "Epoch 64/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5079 - accuracy: 0.7779 - val_loss: 0.5406 - val_accuracy: 0.7120\n",
      "Epoch 65/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5069 - accuracy: 0.7807 - val_loss: 0.5415 - val_accuracy: 0.7120\n",
      "Epoch 66/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5062 - accuracy: 0.7807 - val_loss: 0.5381 - val_accuracy: 0.7174\n",
      "Epoch 67/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5045 - accuracy: 0.7807 - val_loss: 0.5423 - val_accuracy: 0.7228\n",
      "Epoch 68/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5039 - accuracy: 0.7738 - val_loss: 0.5385 - val_accuracy: 0.7228\n",
      "Epoch 69/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5017 - accuracy: 0.7820 - val_loss: 0.5332 - val_accuracy: 0.7283\n",
      "Epoch 70/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5025 - accuracy: 0.7752 - val_loss: 0.5342 - val_accuracy: 0.7283\n",
      "Epoch 71/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4989 - accuracy: 0.7834 - val_loss: 0.5316 - val_accuracy: 0.7228\n",
      "Epoch 72/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4978 - accuracy: 0.7834 - val_loss: 0.5341 - val_accuracy: 0.7283\n",
      "Epoch 73/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4969 - accuracy: 0.7779 - val_loss: 0.5297 - val_accuracy: 0.7283\n",
      "Epoch 74/600\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4963 - accuracy: 0.7834 - val_loss: 0.5318 - val_accuracy: 0.7283\n",
      "Epoch 75/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4944 - accuracy: 0.7820 - val_loss: 0.5254 - val_accuracy: 0.7228\n",
      "Epoch 76/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4929 - accuracy: 0.7793 - val_loss: 0.5300 - val_accuracy: 0.7337\n",
      "Epoch 77/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4938 - accuracy: 0.7834 - val_loss: 0.5255 - val_accuracy: 0.7337\n",
      "Epoch 78/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4914 - accuracy: 0.7861 - val_loss: 0.5257 - val_accuracy: 0.7337\n",
      "Epoch 79/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4898 - accuracy: 0.7847 - val_loss: 0.5238 - val_accuracy: 0.7283\n",
      "Epoch 80/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4887 - accuracy: 0.7847 - val_loss: 0.5251 - val_accuracy: 0.7337\n",
      "Epoch 81/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4897 - accuracy: 0.7793 - val_loss: 0.5207 - val_accuracy: 0.7337\n",
      "Epoch 82/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4900 - accuracy: 0.7820 - val_loss: 0.5190 - val_accuracy: 0.7283\n",
      "Epoch 83/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4849 - accuracy: 0.7861 - val_loss: 0.5251 - val_accuracy: 0.7337\n",
      "Epoch 84/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4856 - accuracy: 0.7888 - val_loss: 0.5194 - val_accuracy: 0.7337\n",
      "Epoch 85/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4851 - accuracy: 0.7820 - val_loss: 0.5173 - val_accuracy: 0.7337\n",
      "Epoch 86/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4840 - accuracy: 0.7902 - val_loss: 0.5232 - val_accuracy: 0.7391\n",
      "Epoch 87/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4860 - accuracy: 0.7888 - val_loss: 0.5124 - val_accuracy: 0.7283\n",
      "Epoch 88/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4797 - accuracy: 0.7956 - val_loss: 0.5258 - val_accuracy: 0.7391\n",
      "Epoch 89/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4804 - accuracy: 0.7929 - val_loss: 0.5120 - val_accuracy: 0.7283\n",
      "Epoch 90/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4783 - accuracy: 0.7916 - val_loss: 0.5164 - val_accuracy: 0.7337\n",
      "Epoch 91/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4776 - accuracy: 0.7943 - val_loss: 0.5163 - val_accuracy: 0.7337\n",
      "Epoch 92/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4771 - accuracy: 0.7888 - val_loss: 0.5129 - val_accuracy: 0.7337\n",
      "Epoch 93/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4773 - accuracy: 0.7916 - val_loss: 0.5067 - val_accuracy: 0.7337\n",
      "Epoch 94/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4746 - accuracy: 0.7888 - val_loss: 0.5200 - val_accuracy: 0.7391\n",
      "Epoch 95/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4754 - accuracy: 0.7984 - val_loss: 0.5077 - val_accuracy: 0.7337\n",
      "Epoch 96/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4725 - accuracy: 0.7956 - val_loss: 0.5055 - val_accuracy: 0.7228\n",
      "Epoch 97/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4712 - accuracy: 0.7956 - val_loss: 0.5098 - val_accuracy: 0.7283\n",
      "Epoch 98/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4713 - accuracy: 0.7970 - val_loss: 0.5085 - val_accuracy: 0.7283\n",
      "Epoch 99/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4717 - accuracy: 0.7888 - val_loss: 0.5022 - val_accuracy: 0.7337\n",
      "Epoch 100/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4703 - accuracy: 0.8025 - val_loss: 0.5095 - val_accuracy: 0.7446\n",
      "Epoch 101/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.7943 - val_loss: 0.4991 - val_accuracy: 0.7337\n",
      "Epoch 102/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4680 - accuracy: 0.8011 - val_loss: 0.5128 - val_accuracy: 0.7446\n",
      "Epoch 103/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4705 - accuracy: 0.7984 - val_loss: 0.4965 - val_accuracy: 0.7446\n",
      "Epoch 104/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4634 - accuracy: 0.8011 - val_loss: 0.5081 - val_accuracy: 0.7446\n",
      "Epoch 105/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4640 - accuracy: 0.8038 - val_loss: 0.4975 - val_accuracy: 0.7391\n",
      "Epoch 106/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4648 - accuracy: 0.7997 - val_loss: 0.4963 - val_accuracy: 0.7391\n",
      "Epoch 107/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4612 - accuracy: 0.8093 - val_loss: 0.5028 - val_accuracy: 0.7446\n",
      "Epoch 108/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4615 - accuracy: 0.8038 - val_loss: 0.4913 - val_accuracy: 0.7500\n",
      "Epoch 109/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4595 - accuracy: 0.8093 - val_loss: 0.5009 - val_accuracy: 0.7446\n",
      "Epoch 110/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4588 - accuracy: 0.8011 - val_loss: 0.4945 - val_accuracy: 0.7446\n",
      "Epoch 111/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4573 - accuracy: 0.8038 - val_loss: 0.4909 - val_accuracy: 0.7446\n",
      "Epoch 112/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4566 - accuracy: 0.8038 - val_loss: 0.4911 - val_accuracy: 0.7446\n",
      "Epoch 113/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.8079 - val_loss: 0.4906 - val_accuracy: 0.7446\n",
      "Epoch 114/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4545 - accuracy: 0.8093 - val_loss: 0.4954 - val_accuracy: 0.7446\n",
      "Epoch 115/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4534 - accuracy: 0.8093 - val_loss: 0.4828 - val_accuracy: 0.7609\n",
      "Epoch 116/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4521 - accuracy: 0.8134 - val_loss: 0.4891 - val_accuracy: 0.7446\n",
      "Epoch 117/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4522 - accuracy: 0.8147 - val_loss: 0.4836 - val_accuracy: 0.7609\n",
      "Epoch 118/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4503 - accuracy: 0.8079 - val_loss: 0.4785 - val_accuracy: 0.7772\n",
      "Epoch 119/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4492 - accuracy: 0.8188 - val_loss: 0.4896 - val_accuracy: 0.7554\n",
      "Epoch 120/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4488 - accuracy: 0.8161 - val_loss: 0.4758 - val_accuracy: 0.7826\n",
      "Epoch 121/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4461 - accuracy: 0.8093 - val_loss: 0.4877 - val_accuracy: 0.7554\n",
      "Epoch 122/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.8161 - val_loss: 0.4755 - val_accuracy: 0.7717\n",
      "Epoch 123/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.8134 - val_loss: 0.4764 - val_accuracy: 0.7717\n",
      "Epoch 124/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.8134 - val_loss: 0.4791 - val_accuracy: 0.7663\n",
      "Epoch 125/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.8229 - val_loss: 0.4746 - val_accuracy: 0.7663\n",
      "Epoch 126/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4444 - accuracy: 0.8147 - val_loss: 0.4740 - val_accuracy: 0.7717\n",
      "Epoch 127/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4396 - accuracy: 0.8120 - val_loss: 0.4809 - val_accuracy: 0.7554\n",
      "Epoch 128/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4394 - accuracy: 0.8243 - val_loss: 0.4712 - val_accuracy: 0.7772\n",
      "Epoch 129/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4375 - accuracy: 0.8202 - val_loss: 0.4705 - val_accuracy: 0.7772\n",
      "Epoch 130/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4374 - accuracy: 0.8161 - val_loss: 0.4689 - val_accuracy: 0.7772\n",
      "Epoch 131/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4378 - accuracy: 0.8161 - val_loss: 0.4694 - val_accuracy: 0.7772\n",
      "Epoch 132/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4345 - accuracy: 0.8243 - val_loss: 0.4719 - val_accuracy: 0.7772\n",
      "Epoch 133/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4357 - accuracy: 0.8229 - val_loss: 0.4619 - val_accuracy: 0.7826\n",
      "Epoch 134/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4336 - accuracy: 0.8215 - val_loss: 0.4654 - val_accuracy: 0.7880\n",
      "Epoch 135/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.8215 - val_loss: 0.4628 - val_accuracy: 0.7935\n",
      "Epoch 136/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4320 - accuracy: 0.8174 - val_loss: 0.4605 - val_accuracy: 0.7935\n",
      "Epoch 137/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4289 - accuracy: 0.8270 - val_loss: 0.4654 - val_accuracy: 0.7826\n",
      "Epoch 138/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4276 - accuracy: 0.8297 - val_loss: 0.4571 - val_accuracy: 0.7989\n",
      "Epoch 139/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.8283 - val_loss: 0.4582 - val_accuracy: 0.7935\n",
      "Epoch 140/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4260 - accuracy: 0.8270 - val_loss: 0.4551 - val_accuracy: 0.7935\n",
      "Epoch 141/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4241 - accuracy: 0.8283 - val_loss: 0.4587 - val_accuracy: 0.7880\n",
      "Epoch 142/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4241 - accuracy: 0.8311 - val_loss: 0.4475 - val_accuracy: 0.7935\n",
      "Epoch 143/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4257 - accuracy: 0.8188 - val_loss: 0.4619 - val_accuracy: 0.7826\n",
      "Epoch 144/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4262 - accuracy: 0.8256 - val_loss: 0.4532 - val_accuracy: 0.7935\n",
      "Epoch 145/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4283 - accuracy: 0.8188 - val_loss: 0.4476 - val_accuracy: 0.7989\n",
      "Epoch 146/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4240 - accuracy: 0.8283 - val_loss: 0.4585 - val_accuracy: 0.7880\n",
      "Epoch 147/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4198 - accuracy: 0.8229 - val_loss: 0.4400 - val_accuracy: 0.7935\n",
      "Epoch 148/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4258 - accuracy: 0.8324 - val_loss: 0.4539 - val_accuracy: 0.7935\n",
      "Epoch 149/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4179 - accuracy: 0.8243 - val_loss: 0.4371 - val_accuracy: 0.7989\n",
      "Epoch 150/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.8311 - val_loss: 0.4561 - val_accuracy: 0.8043\n",
      "Epoch 151/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4138 - accuracy: 0.8351 - val_loss: 0.4379 - val_accuracy: 0.7989\n",
      "Epoch 152/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4162 - accuracy: 0.8256 - val_loss: 0.4429 - val_accuracy: 0.8043\n",
      "Epoch 153/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4217 - accuracy: 0.8283 - val_loss: 0.4345 - val_accuracy: 0.8043\n",
      "Epoch 154/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4127 - accuracy: 0.8297 - val_loss: 0.4370 - val_accuracy: 0.7989\n",
      "Epoch 155/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4105 - accuracy: 0.8406 - val_loss: 0.4395 - val_accuracy: 0.8098\n",
      "Epoch 156/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4091 - accuracy: 0.8351 - val_loss: 0.4360 - val_accuracy: 0.8043\n",
      "Epoch 157/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4100 - accuracy: 0.8365 - val_loss: 0.4315 - val_accuracy: 0.7989\n",
      "Epoch 158/600\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4090 - accuracy: 0.8283 - val_loss: 0.4315 - val_accuracy: 0.8043\n",
      "Epoch 159/600\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4090 - accuracy: 0.8392 - val_loss: 0.4342 - val_accuracy: 0.8152\n",
      "Epoch 160/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4065 - accuracy: 0.8351 - val_loss: 0.4289 - val_accuracy: 0.8098\n",
      "Epoch 161/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4036 - accuracy: 0.8365 - val_loss: 0.4295 - val_accuracy: 0.8098\n",
      "Epoch 162/600\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.4044 - accuracy: 0.8351 - val_loss: 0.4250 - val_accuracy: 0.8098\n",
      "Epoch 163/600\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4033 - accuracy: 0.8379 - val_loss: 0.4285 - val_accuracy: 0.8207\n",
      "Epoch 164/600\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4013 - accuracy: 0.8365 - val_loss: 0.4253 - val_accuracy: 0.8152\n",
      "Epoch 165/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3994 - accuracy: 0.8379 - val_loss: 0.4224 - val_accuracy: 0.8098\n",
      "Epoch 166/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3988 - accuracy: 0.8365 - val_loss: 0.4277 - val_accuracy: 0.8152\n",
      "Epoch 167/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3977 - accuracy: 0.8406 - val_loss: 0.4150 - val_accuracy: 0.8315\n",
      "Epoch 168/600\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3975 - accuracy: 0.8351 - val_loss: 0.4240 - val_accuracy: 0.8152\n",
      "Epoch 169/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3957 - accuracy: 0.8406 - val_loss: 0.4197 - val_accuracy: 0.8207\n",
      "Epoch 170/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3942 - accuracy: 0.8406 - val_loss: 0.4219 - val_accuracy: 0.8152\n",
      "Epoch 171/600\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3958 - accuracy: 0.8406 - val_loss: 0.4144 - val_accuracy: 0.8261\n",
      "Epoch 172/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3925 - accuracy: 0.8351 - val_loss: 0.4227 - val_accuracy: 0.8207\n",
      "Epoch 173/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3933 - accuracy: 0.8351 - val_loss: 0.4091 - val_accuracy: 0.8207\n",
      "Epoch 174/600\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3909 - accuracy: 0.8501 - val_loss: 0.4239 - val_accuracy: 0.8207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3916 - accuracy: 0.8365 - val_loss: 0.4101 - val_accuracy: 0.8207\n",
      "Epoch 176/600\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3879 - accuracy: 0.8420 - val_loss: 0.4210 - val_accuracy: 0.8207\n",
      "Epoch 177/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3922 - accuracy: 0.8406 - val_loss: 0.4064 - val_accuracy: 0.8315\n",
      "Epoch 178/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3930 - accuracy: 0.8379 - val_loss: 0.4124 - val_accuracy: 0.8207\n",
      "Epoch 179/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3910 - accuracy: 0.8379 - val_loss: 0.4106 - val_accuracy: 0.8207\n",
      "Epoch 180/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3850 - accuracy: 0.8406 - val_loss: 0.3997 - val_accuracy: 0.8370\n",
      "Epoch 181/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3875 - accuracy: 0.8447 - val_loss: 0.4114 - val_accuracy: 0.8207\n",
      "Epoch 182/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3856 - accuracy: 0.8433 - val_loss: 0.4008 - val_accuracy: 0.8207\n",
      "Epoch 183/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3825 - accuracy: 0.8447 - val_loss: 0.4082 - val_accuracy: 0.8261\n",
      "Epoch 184/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3819 - accuracy: 0.8460 - val_loss: 0.4031 - val_accuracy: 0.8261\n",
      "Epoch 185/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3802 - accuracy: 0.8447 - val_loss: 0.4004 - val_accuracy: 0.8261\n",
      "Epoch 186/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3787 - accuracy: 0.8488 - val_loss: 0.4040 - val_accuracy: 0.8261\n",
      "Epoch 187/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3802 - accuracy: 0.8447 - val_loss: 0.4042 - val_accuracy: 0.8261\n",
      "Epoch 188/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3820 - accuracy: 0.8474 - val_loss: 0.3907 - val_accuracy: 0.8370\n",
      "Epoch 189/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3847 - accuracy: 0.8351 - val_loss: 0.4037 - val_accuracy: 0.8261\n",
      "Epoch 190/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3792 - accuracy: 0.8460 - val_loss: 0.3990 - val_accuracy: 0.8261\n",
      "Epoch 191/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3771 - accuracy: 0.8447 - val_loss: 0.3930 - val_accuracy: 0.8370\n",
      "Epoch 192/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3760 - accuracy: 0.8488 - val_loss: 0.3945 - val_accuracy: 0.8315\n",
      "Epoch 193/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3773 - accuracy: 0.8474 - val_loss: 0.3960 - val_accuracy: 0.8207\n",
      "Epoch 194/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3757 - accuracy: 0.8529 - val_loss: 0.3894 - val_accuracy: 0.8315\n",
      "Epoch 195/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3725 - accuracy: 0.8501 - val_loss: 0.3891 - val_accuracy: 0.8315\n",
      "Epoch 196/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3731 - accuracy: 0.8474 - val_loss: 0.3967 - val_accuracy: 0.8315\n",
      "Epoch 197/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3718 - accuracy: 0.8501 - val_loss: 0.3856 - val_accuracy: 0.8261\n",
      "Epoch 198/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3711 - accuracy: 0.8501 - val_loss: 0.3913 - val_accuracy: 0.8370\n",
      "Epoch 199/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3676 - accuracy: 0.8542 - val_loss: 0.3817 - val_accuracy: 0.8424\n",
      "Epoch 200/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3689 - accuracy: 0.8529 - val_loss: 0.3970 - val_accuracy: 0.8424\n",
      "Epoch 201/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3675 - accuracy: 0.8542 - val_loss: 0.3830 - val_accuracy: 0.8261\n",
      "Epoch 202/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3709 - accuracy: 0.8460 - val_loss: 0.3921 - val_accuracy: 0.8424\n",
      "Epoch 203/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3691 - accuracy: 0.8569 - val_loss: 0.3826 - val_accuracy: 0.8261\n",
      "Epoch 204/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3661 - accuracy: 0.8447 - val_loss: 0.3807 - val_accuracy: 0.8261\n",
      "Epoch 205/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3640 - accuracy: 0.8583 - val_loss: 0.3900 - val_accuracy: 0.8478\n",
      "Epoch 206/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3624 - accuracy: 0.8529 - val_loss: 0.3766 - val_accuracy: 0.8424\n",
      "Epoch 207/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3628 - accuracy: 0.8515 - val_loss: 0.3836 - val_accuracy: 0.8424\n",
      "Epoch 208/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3623 - accuracy: 0.8556 - val_loss: 0.3763 - val_accuracy: 0.8424\n",
      "Epoch 209/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3609 - accuracy: 0.8542 - val_loss: 0.3853 - val_accuracy: 0.8424\n",
      "Epoch 210/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3608 - accuracy: 0.8569 - val_loss: 0.3730 - val_accuracy: 0.8478\n",
      "Epoch 211/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3689 - accuracy: 0.8474 - val_loss: 0.3965 - val_accuracy: 0.8478\n",
      "Epoch 212/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3659 - accuracy: 0.8569 - val_loss: 0.3685 - val_accuracy: 0.8424\n",
      "Epoch 213/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3723 - accuracy: 0.8474 - val_loss: 0.3894 - val_accuracy: 0.8533\n",
      "Epoch 214/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3744 - accuracy: 0.8488 - val_loss: 0.3669 - val_accuracy: 0.8424\n",
      "Epoch 215/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3611 - accuracy: 0.8529 - val_loss: 0.3785 - val_accuracy: 0.8424\n",
      "Epoch 216/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3575 - accuracy: 0.8569 - val_loss: 0.3721 - val_accuracy: 0.8424\n",
      "Epoch 217/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3555 - accuracy: 0.8515 - val_loss: 0.3709 - val_accuracy: 0.8478\n",
      "Epoch 218/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3545 - accuracy: 0.8529 - val_loss: 0.3768 - val_accuracy: 0.8478\n",
      "Epoch 219/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3556 - accuracy: 0.8597 - val_loss: 0.3673 - val_accuracy: 0.8478\n",
      "Epoch 220/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3625 - accuracy: 0.8501 - val_loss: 0.3816 - val_accuracy: 0.8478\n",
      "Epoch 221/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3549 - accuracy: 0.8583 - val_loss: 0.3651 - val_accuracy: 0.8478\n",
      "Epoch 222/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3566 - accuracy: 0.8569 - val_loss: 0.3702 - val_accuracy: 0.8478\n",
      "Epoch 223/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3545 - accuracy: 0.8529 - val_loss: 0.3693 - val_accuracy: 0.8478\n",
      "Epoch 224/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3522 - accuracy: 0.8542 - val_loss: 0.3676 - val_accuracy: 0.8478\n",
      "Epoch 225/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3538 - accuracy: 0.8556 - val_loss: 0.3753 - val_accuracy: 0.8478\n",
      "Epoch 226/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3539 - accuracy: 0.8610 - val_loss: 0.3658 - val_accuracy: 0.8533\n",
      "Epoch 227/600\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3586 - accuracy: 0.8474 - val_loss: 0.3727 - val_accuracy: 0.8478\n",
      "Epoch 228/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3568 - accuracy: 0.8529 - val_loss: 0.3595 - val_accuracy: 0.8587\n",
      "Epoch 229/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3540 - accuracy: 0.8583 - val_loss: 0.3709 - val_accuracy: 0.8533\n",
      "Epoch 230/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3496 - accuracy: 0.8610 - val_loss: 0.3726 - val_accuracy: 0.8478\n",
      "Epoch 231/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3486 - accuracy: 0.8556 - val_loss: 0.3596 - val_accuracy: 0.8641\n",
      "Epoch 232/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3504 - accuracy: 0.8515 - val_loss: 0.3741 - val_accuracy: 0.8478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3494 - accuracy: 0.8529 - val_loss: 0.3597 - val_accuracy: 0.8641\n",
      "Epoch 234/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3488 - accuracy: 0.8597 - val_loss: 0.3586 - val_accuracy: 0.8641\n",
      "Epoch 235/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3515 - accuracy: 0.8583 - val_loss: 0.3710 - val_accuracy: 0.8478\n",
      "Epoch 236/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3519 - accuracy: 0.8678 - val_loss: 0.3573 - val_accuracy: 0.8641\n",
      "Epoch 237/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3494 - accuracy: 0.8529 - val_loss: 0.3590 - val_accuracy: 0.8641\n",
      "Epoch 238/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3461 - accuracy: 0.8569 - val_loss: 0.3627 - val_accuracy: 0.8533\n",
      "Epoch 239/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3479 - accuracy: 0.8610 - val_loss: 0.3588 - val_accuracy: 0.8641\n",
      "Epoch 240/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3481 - accuracy: 0.8529 - val_loss: 0.3614 - val_accuracy: 0.8533\n",
      "Epoch 241/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.8624 - val_loss: 0.3570 - val_accuracy: 0.8641\n",
      "Epoch 242/600\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.79 - 0s 7ms/step - loss: 0.3450 - accuracy: 0.8542 - val_loss: 0.3550 - val_accuracy: 0.8641\n",
      "Epoch 243/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3449 - accuracy: 0.8638 - val_loss: 0.3649 - val_accuracy: 0.8424\n",
      "Epoch 244/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3416 - accuracy: 0.8610 - val_loss: 0.3519 - val_accuracy: 0.8641\n",
      "Epoch 245/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3419 - accuracy: 0.8597 - val_loss: 0.3629 - val_accuracy: 0.8424\n",
      "Epoch 246/600\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3441 - accuracy: 0.8597 - val_loss: 0.3625 - val_accuracy: 0.8424\n",
      "Epoch 247/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3410 - accuracy: 0.8583 - val_loss: 0.3573 - val_accuracy: 0.8587\n",
      "Epoch 248/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3410 - accuracy: 0.8624 - val_loss: 0.3617 - val_accuracy: 0.8424\n",
      "Epoch 249/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3410 - accuracy: 0.8610 - val_loss: 0.3595 - val_accuracy: 0.8478\n",
      "Epoch 250/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3398 - accuracy: 0.8597 - val_loss: 0.3527 - val_accuracy: 0.8587\n",
      "Epoch 251/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3400 - accuracy: 0.8638 - val_loss: 0.3524 - val_accuracy: 0.8587\n",
      "Epoch 252/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3391 - accuracy: 0.8624 - val_loss: 0.3561 - val_accuracy: 0.8533\n",
      "Epoch 253/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3388 - accuracy: 0.8624 - val_loss: 0.3539 - val_accuracy: 0.8587\n",
      "Epoch 254/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3388 - accuracy: 0.8651 - val_loss: 0.3545 - val_accuracy: 0.8533\n",
      "Epoch 255/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3419 - accuracy: 0.8638 - val_loss: 0.3500 - val_accuracy: 0.8587\n",
      "Epoch 256/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3391 - accuracy: 0.8597 - val_loss: 0.3533 - val_accuracy: 0.8533\n",
      "Epoch 257/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3379 - accuracy: 0.8638 - val_loss: 0.3587 - val_accuracy: 0.8478\n",
      "Epoch 258/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3384 - accuracy: 0.8610 - val_loss: 0.3522 - val_accuracy: 0.8533\n",
      "Epoch 259/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3381 - accuracy: 0.8597 - val_loss: 0.3585 - val_accuracy: 0.8478\n",
      "Epoch 260/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3394 - accuracy: 0.8638 - val_loss: 0.3423 - val_accuracy: 0.8804\n",
      "Epoch 261/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3440 - accuracy: 0.8597 - val_loss: 0.3646 - val_accuracy: 0.8533\n",
      "Epoch 262/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3405 - accuracy: 0.8624 - val_loss: 0.3423 - val_accuracy: 0.8750\n",
      "Epoch 263/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3454 - accuracy: 0.8529 - val_loss: 0.3630 - val_accuracy: 0.8478\n",
      "Epoch 264/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3415 - accuracy: 0.8665 - val_loss: 0.3435 - val_accuracy: 0.8696\n",
      "Epoch 265/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3405 - accuracy: 0.8597 - val_loss: 0.3622 - val_accuracy: 0.8533\n",
      "Epoch 266/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3369 - accuracy: 0.8610 - val_loss: 0.3464 - val_accuracy: 0.8587\n",
      "Epoch 267/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3351 - accuracy: 0.8624 - val_loss: 0.3488 - val_accuracy: 0.8533\n",
      "Epoch 268/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3348 - accuracy: 0.8665 - val_loss: 0.3541 - val_accuracy: 0.8533\n",
      "Epoch 269/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3332 - accuracy: 0.8665 - val_loss: 0.3442 - val_accuracy: 0.8587\n",
      "Epoch 270/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3345 - accuracy: 0.8638 - val_loss: 0.3543 - val_accuracy: 0.8533\n",
      "Epoch 271/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3374 - accuracy: 0.8678 - val_loss: 0.3442 - val_accuracy: 0.8587\n",
      "Epoch 272/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3362 - accuracy: 0.8624 - val_loss: 0.3465 - val_accuracy: 0.8478\n",
      "Epoch 273/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3343 - accuracy: 0.8678 - val_loss: 0.3538 - val_accuracy: 0.8533\n",
      "Epoch 274/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3338 - accuracy: 0.8638 - val_loss: 0.3559 - val_accuracy: 0.8533\n",
      "Epoch 275/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3387 - accuracy: 0.8583 - val_loss: 0.3503 - val_accuracy: 0.8533\n",
      "Epoch 276/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3388 - accuracy: 0.8638 - val_loss: 0.3447 - val_accuracy: 0.8533\n",
      "Epoch 277/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3390 - accuracy: 0.8542 - val_loss: 0.3561 - val_accuracy: 0.8533\n",
      "Epoch 278/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3353 - accuracy: 0.8651 - val_loss: 0.3415 - val_accuracy: 0.8587\n",
      "Epoch 279/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3341 - accuracy: 0.8638 - val_loss: 0.3560 - val_accuracy: 0.8533\n",
      "Epoch 280/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3363 - accuracy: 0.8678 - val_loss: 0.3419 - val_accuracy: 0.8587\n",
      "Epoch 281/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3341 - accuracy: 0.8651 - val_loss: 0.3490 - val_accuracy: 0.8478\n",
      "Epoch 282/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3329 - accuracy: 0.8678 - val_loss: 0.3505 - val_accuracy: 0.8533\n",
      "Epoch 283/600\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 0.91 - 0s 8ms/step - loss: 0.3313 - accuracy: 0.8651 - val_loss: 0.3392 - val_accuracy: 0.8641\n",
      "Epoch 284/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3320 - accuracy: 0.8638 - val_loss: 0.3504 - val_accuracy: 0.8587\n",
      "Epoch 285/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.8665 - val_loss: 0.3495 - val_accuracy: 0.8533\n",
      "Epoch 286/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3306 - accuracy: 0.8692 - val_loss: 0.3471 - val_accuracy: 0.8478\n",
      "Epoch 287/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3310 - accuracy: 0.8651 - val_loss: 0.3461 - val_accuracy: 0.8533\n",
      "Epoch 288/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3305 - accuracy: 0.8651 - val_loss: 0.3447 - val_accuracy: 0.8533\n",
      "Epoch 289/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3297 - accuracy: 0.8692 - val_loss: 0.3431 - val_accuracy: 0.8533\n",
      "Epoch 290/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3300 - accuracy: 0.8651 - val_loss: 0.3502 - val_accuracy: 0.8533\n",
      "Epoch 291/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3371 - accuracy: 0.8624 - val_loss: 0.3493 - val_accuracy: 0.8533\n",
      "Epoch 292/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3359 - accuracy: 0.8692 - val_loss: 0.3451 - val_accuracy: 0.8533\n",
      "Epoch 293/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3305 - accuracy: 0.8665 - val_loss: 0.3470 - val_accuracy: 0.8533\n",
      "Epoch 294/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3310 - accuracy: 0.8706 - val_loss: 0.3383 - val_accuracy: 0.8587\n",
      "Epoch 295/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3293 - accuracy: 0.8692 - val_loss: 0.3478 - val_accuracy: 0.8533\n",
      "Epoch 296/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3281 - accuracy: 0.8678 - val_loss: 0.3424 - val_accuracy: 0.8533\n",
      "Epoch 297/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3280 - accuracy: 0.8692 - val_loss: 0.3428 - val_accuracy: 0.8587\n",
      "Epoch 298/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3289 - accuracy: 0.8719 - val_loss: 0.3408 - val_accuracy: 0.8587\n",
      "Epoch 299/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3281 - accuracy: 0.8692 - val_loss: 0.3526 - val_accuracy: 0.8533\n",
      "Epoch 300/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3284 - accuracy: 0.8665 - val_loss: 0.3400 - val_accuracy: 0.8587\n",
      "Epoch 301/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3292 - accuracy: 0.8678 - val_loss: 0.3573 - val_accuracy: 0.8533\n",
      "Epoch 302/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3298 - accuracy: 0.8624 - val_loss: 0.3393 - val_accuracy: 0.8587\n",
      "Epoch 303/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3281 - accuracy: 0.8692 - val_loss: 0.3452 - val_accuracy: 0.8587\n",
      "Epoch 304/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3296 - accuracy: 0.8706 - val_loss: 0.3463 - val_accuracy: 0.8587\n",
      "Epoch 305/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3270 - accuracy: 0.8678 - val_loss: 0.3476 - val_accuracy: 0.8587\n",
      "Epoch 306/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3295 - accuracy: 0.8706 - val_loss: 0.3485 - val_accuracy: 0.8533\n",
      "Epoch 307/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3307 - accuracy: 0.8692 - val_loss: 0.3382 - val_accuracy: 0.8587\n",
      "Epoch 308/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3282 - accuracy: 0.8651 - val_loss: 0.3425 - val_accuracy: 0.8587\n",
      "Epoch 309/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3317 - accuracy: 0.8651 - val_loss: 0.3514 - val_accuracy: 0.8533\n",
      "Epoch 310/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3303 - accuracy: 0.8638 - val_loss: 0.3358 - val_accuracy: 0.8587\n",
      "Epoch 311/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3274 - accuracy: 0.8706 - val_loss: 0.3494 - val_accuracy: 0.8533\n",
      "Epoch 312/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3300 - accuracy: 0.8610 - val_loss: 0.3354 - val_accuracy: 0.8587\n",
      "Epoch 313/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3321 - accuracy: 0.8651 - val_loss: 0.3589 - val_accuracy: 0.8641\n",
      "Epoch 314/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3278 - accuracy: 0.8678 - val_loss: 0.3367 - val_accuracy: 0.8587\n",
      "Epoch 315/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3267 - accuracy: 0.8719 - val_loss: 0.3504 - val_accuracy: 0.8587\n",
      "Epoch 316/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3400 - accuracy: 0.8569 - val_loss: 0.3305 - val_accuracy: 0.8750\n",
      "Epoch 317/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3517 - accuracy: 0.8597 - val_loss: 0.3645 - val_accuracy: 0.8533\n",
      "Epoch 318/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3526 - accuracy: 0.8569 - val_loss: 0.3313 - val_accuracy: 0.8641\n",
      "Epoch 319/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3516 - accuracy: 0.8583 - val_loss: 0.3537 - val_accuracy: 0.8533\n",
      "Epoch 320/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3342 - accuracy: 0.8665 - val_loss: 0.3415 - val_accuracy: 0.8587\n",
      "Epoch 321/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3382 - accuracy: 0.8651 - val_loss: 0.3420 - val_accuracy: 0.8587\n",
      "Epoch 322/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3314 - accuracy: 0.8638 - val_loss: 0.3524 - val_accuracy: 0.8533\n",
      "Epoch 323/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3315 - accuracy: 0.8678 - val_loss: 0.3357 - val_accuracy: 0.8641\n",
      "Epoch 324/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3273 - accuracy: 0.8638 - val_loss: 0.3477 - val_accuracy: 0.8641\n",
      "Epoch 325/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3229 - accuracy: 0.8719 - val_loss: 0.3319 - val_accuracy: 0.8587\n",
      "Epoch 326/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3306 - accuracy: 0.8719 - val_loss: 0.3491 - val_accuracy: 0.8641\n",
      "Epoch 327/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3329 - accuracy: 0.8665 - val_loss: 0.3397 - val_accuracy: 0.8641\n",
      "Epoch 328/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3307 - accuracy: 0.8597 - val_loss: 0.3396 - val_accuracy: 0.8641\n",
      "Epoch 329/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3286 - accuracy: 0.8706 - val_loss: 0.3421 - val_accuracy: 0.8587\n",
      "Epoch 330/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3247 - accuracy: 0.8678 - val_loss: 0.3433 - val_accuracy: 0.8587\n",
      "Epoch 331/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3250 - accuracy: 0.8692 - val_loss: 0.3367 - val_accuracy: 0.8641\n",
      "Epoch 332/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3288 - accuracy: 0.8651 - val_loss: 0.3387 - val_accuracy: 0.8641\n",
      "Epoch 333/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3265 - accuracy: 0.8678 - val_loss: 0.3374 - val_accuracy: 0.8641\n",
      "Epoch 334/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3260 - accuracy: 0.8665 - val_loss: 0.3414 - val_accuracy: 0.8587\n",
      "Epoch 335/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3265 - accuracy: 0.8747 - val_loss: 0.3375 - val_accuracy: 0.8641\n",
      "Epoch 336/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3246 - accuracy: 0.8665 - val_loss: 0.3454 - val_accuracy: 0.8641\n",
      "Epoch 337/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3258 - accuracy: 0.8692 - val_loss: 0.3376 - val_accuracy: 0.8641\n",
      "Epoch 338/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3227 - accuracy: 0.8692 - val_loss: 0.3462 - val_accuracy: 0.8641\n",
      "Epoch 339/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3235 - accuracy: 0.8706 - val_loss: 0.3355 - val_accuracy: 0.8641\n",
      "Epoch 340/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3245 - accuracy: 0.8733 - val_loss: 0.3379 - val_accuracy: 0.8641\n",
      "Epoch 341/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3222 - accuracy: 0.8706 - val_loss: 0.3482 - val_accuracy: 0.8641\n",
      "Epoch 342/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3235 - accuracy: 0.8678 - val_loss: 0.3345 - val_accuracy: 0.8587\n",
      "Epoch 343/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3261 - accuracy: 0.8760 - val_loss: 0.3492 - val_accuracy: 0.8641\n",
      "Epoch 344/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3252 - accuracy: 0.8651 - val_loss: 0.3384 - val_accuracy: 0.8696\n",
      "Epoch 345/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3249 - accuracy: 0.8733 - val_loss: 0.3397 - val_accuracy: 0.8696\n",
      "Epoch 346/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3238 - accuracy: 0.8638 - val_loss: 0.3406 - val_accuracy: 0.8641\n",
      "Epoch 347/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3223 - accuracy: 0.8719 - val_loss: 0.3332 - val_accuracy: 0.8587\n",
      "Epoch 348/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3234 - accuracy: 0.8719 - val_loss: 0.3379 - val_accuracy: 0.8696\n",
      "Epoch 349/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3238 - accuracy: 0.8719 - val_loss: 0.3458 - val_accuracy: 0.8641\n",
      "Epoch 350/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3298 - accuracy: 0.8638 - val_loss: 0.3317 - val_accuracy: 0.8587\n",
      "Epoch 351/600\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8678 - val_loss: 0.3331 - val_accuracy: 0.8587\n",
      "Epoch 352/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3219 - accuracy: 0.8678 - val_loss: 0.3482 - val_accuracy: 0.8696\n",
      "Epoch 353/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3242 - accuracy: 0.8692 - val_loss: 0.3279 - val_accuracy: 0.8696\n",
      "Epoch 354/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3241 - accuracy: 0.8706 - val_loss: 0.3478 - val_accuracy: 0.8696\n",
      "Epoch 355/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3225 - accuracy: 0.8665 - val_loss: 0.3324 - val_accuracy: 0.8641\n",
      "Epoch 356/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3236 - accuracy: 0.8733 - val_loss: 0.3408 - val_accuracy: 0.8641\n",
      "Epoch 357/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3228 - accuracy: 0.8706 - val_loss: 0.3381 - val_accuracy: 0.8696\n",
      "Epoch 358/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3214 - accuracy: 0.8719 - val_loss: 0.3356 - val_accuracy: 0.8696\n",
      "Epoch 359/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3276 - accuracy: 0.8733 - val_loss: 0.3403 - val_accuracy: 0.8641\n",
      "Epoch 360/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3266 - accuracy: 0.8651 - val_loss: 0.3420 - val_accuracy: 0.8641\n",
      "Epoch 361/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3265 - accuracy: 0.8706 - val_loss: 0.3348 - val_accuracy: 0.8696\n",
      "Epoch 362/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3220 - accuracy: 0.8651 - val_loss: 0.3488 - val_accuracy: 0.8696\n",
      "Epoch 363/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3230 - accuracy: 0.8774 - val_loss: 0.3305 - val_accuracy: 0.8696\n",
      "Epoch 364/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3228 - accuracy: 0.8719 - val_loss: 0.3498 - val_accuracy: 0.8696\n",
      "Epoch 365/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3246 - accuracy: 0.8706 - val_loss: 0.3308 - val_accuracy: 0.8696\n",
      "Epoch 366/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3218 - accuracy: 0.8747 - val_loss: 0.3404 - val_accuracy: 0.8641\n",
      "Epoch 367/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3218 - accuracy: 0.8733 - val_loss: 0.3375 - val_accuracy: 0.8696\n",
      "Epoch 368/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3211 - accuracy: 0.8719 - val_loss: 0.3427 - val_accuracy: 0.8696\n",
      "Epoch 369/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3216 - accuracy: 0.8692 - val_loss: 0.3332 - val_accuracy: 0.8696\n",
      "Epoch 370/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3242 - accuracy: 0.8706 - val_loss: 0.3378 - val_accuracy: 0.8696\n",
      "Epoch 371/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3239 - accuracy: 0.8665 - val_loss: 0.3361 - val_accuracy: 0.8696\n",
      "Epoch 372/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3221 - accuracy: 0.8719 - val_loss: 0.3304 - val_accuracy: 0.8750\n",
      "Epoch 373/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3221 - accuracy: 0.8706 - val_loss: 0.3434 - val_accuracy: 0.8696\n",
      "Epoch 374/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3204 - accuracy: 0.8719 - val_loss: 0.3296 - val_accuracy: 0.8696\n",
      "Epoch 375/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3210 - accuracy: 0.8733 - val_loss: 0.3387 - val_accuracy: 0.8696\n",
      "Epoch 376/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3208 - accuracy: 0.8719 - val_loss: 0.3375 - val_accuracy: 0.8696\n",
      "Epoch 377/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3201 - accuracy: 0.8733 - val_loss: 0.3372 - val_accuracy: 0.8696\n",
      "Epoch 378/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3204 - accuracy: 0.8747 - val_loss: 0.3364 - val_accuracy: 0.8696\n",
      "Epoch 379/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3215 - accuracy: 0.8774 - val_loss: 0.3348 - val_accuracy: 0.8696\n",
      "Epoch 380/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3221 - accuracy: 0.8733 - val_loss: 0.3377 - val_accuracy: 0.8696\n",
      "Epoch 381/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3220 - accuracy: 0.8747 - val_loss: 0.3341 - val_accuracy: 0.8696\n",
      "Epoch 382/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3234 - accuracy: 0.8760 - val_loss: 0.3361 - val_accuracy: 0.8696\n",
      "Epoch 383/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3258 - accuracy: 0.8747 - val_loss: 0.3342 - val_accuracy: 0.8696\n",
      "Epoch 384/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3242 - accuracy: 0.8747 - val_loss: 0.3376 - val_accuracy: 0.8696\n",
      "Epoch 385/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3233 - accuracy: 0.8733 - val_loss: 0.3330 - val_accuracy: 0.8696\n",
      "Epoch 386/600\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3252 - accuracy: 0.8733 - val_loss: 0.3629 - val_accuracy: 0.8533\n",
      "Epoch 387/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3380 - accuracy: 0.8583 - val_loss: 0.3239 - val_accuracy: 0.8641\n",
      "Epoch 388/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3336 - accuracy: 0.8678 - val_loss: 0.3470 - val_accuracy: 0.8696\n",
      "Epoch 389/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3292 - accuracy: 0.8597 - val_loss: 0.3315 - val_accuracy: 0.8750\n",
      "Epoch 390/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3289 - accuracy: 0.8733 - val_loss: 0.3357 - val_accuracy: 0.8696\n",
      "Epoch 391/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3220 - accuracy: 0.8678 - val_loss: 0.3410 - val_accuracy: 0.8696\n",
      "Epoch 392/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3265 - accuracy: 0.8719 - val_loss: 0.3350 - val_accuracy: 0.8696\n",
      "Epoch 393/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3232 - accuracy: 0.8733 - val_loss: 0.3356 - val_accuracy: 0.8696\n",
      "Epoch 394/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3199 - accuracy: 0.8760 - val_loss: 0.3287 - val_accuracy: 0.8750\n",
      "Epoch 395/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3213 - accuracy: 0.8692 - val_loss: 0.3410 - val_accuracy: 0.8696\n",
      "Epoch 396/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3254 - accuracy: 0.8733 - val_loss: 0.3370 - val_accuracy: 0.8750\n",
      "Epoch 397/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3200 - accuracy: 0.8760 - val_loss: 0.3352 - val_accuracy: 0.8696\n",
      "Epoch 398/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3207 - accuracy: 0.8719 - val_loss: 0.3349 - val_accuracy: 0.8696\n",
      "Epoch 399/600\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.3210 - accuracy: 0.8774 - val_loss: 0.3315 - val_accuracy: 0.8750\n",
      "Epoch 400/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3193 - accuracy: 0.8747 - val_loss: 0.3419 - val_accuracy: 0.8696\n",
      "Epoch 401/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3242 - accuracy: 0.8747 - val_loss: 0.3348 - val_accuracy: 0.8696\n",
      "Epoch 402/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3224 - accuracy: 0.8760 - val_loss: 0.3410 - val_accuracy: 0.8696\n",
      "Epoch 403/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3194 - accuracy: 0.8733 - val_loss: 0.3309 - val_accuracy: 0.8750\n",
      "Epoch 404/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3208 - accuracy: 0.8747 - val_loss: 0.3320 - val_accuracy: 0.8750\n",
      "Epoch 405/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3205 - accuracy: 0.8760 - val_loss: 0.3337 - val_accuracy: 0.8696\n",
      "Epoch 406/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3217 - accuracy: 0.8706 - val_loss: 0.3344 - val_accuracy: 0.8696\n",
      "Epoch 407/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3239 - accuracy: 0.8747 - val_loss: 0.3276 - val_accuracy: 0.8804\n",
      "Epoch 408/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3280 - accuracy: 0.8597 - val_loss: 0.3404 - val_accuracy: 0.8696\n",
      "Epoch 409/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3257 - accuracy: 0.8747 - val_loss: 0.3318 - val_accuracy: 0.8750\n",
      "Epoch 410/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3235 - accuracy: 0.8706 - val_loss: 0.3351 - val_accuracy: 0.8750\n",
      "Epoch 411/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3207 - accuracy: 0.8747 - val_loss: 0.3309 - val_accuracy: 0.8750\n",
      "Epoch 412/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3192 - accuracy: 0.8760 - val_loss: 0.3387 - val_accuracy: 0.8750\n",
      "Epoch 413/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3188 - accuracy: 0.8747 - val_loss: 0.3326 - val_accuracy: 0.8750\n",
      "Epoch 414/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3198 - accuracy: 0.8760 - val_loss: 0.3391 - val_accuracy: 0.8750\n",
      "Epoch 415/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3208 - accuracy: 0.8706 - val_loss: 0.3317 - val_accuracy: 0.8750\n",
      "Epoch 416/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3247 - accuracy: 0.8719 - val_loss: 0.3403 - val_accuracy: 0.8696\n",
      "Epoch 417/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3253 - accuracy: 0.8678 - val_loss: 0.3356 - val_accuracy: 0.8750\n",
      "Epoch 418/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3188 - accuracy: 0.8733 - val_loss: 0.3268 - val_accuracy: 0.8804\n",
      "Epoch 419/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3229 - accuracy: 0.8733 - val_loss: 0.3391 - val_accuracy: 0.8750\n",
      "Epoch 420/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3185 - accuracy: 0.8747 - val_loss: 0.3273 - val_accuracy: 0.8804\n",
      "Epoch 421/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3220 - accuracy: 0.8719 - val_loss: 0.3354 - val_accuracy: 0.8750\n",
      "Epoch 422/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3223 - accuracy: 0.8719 - val_loss: 0.3351 - val_accuracy: 0.8750\n",
      "Epoch 423/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3193 - accuracy: 0.8733 - val_loss: 0.3345 - val_accuracy: 0.8750\n",
      "Epoch 424/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3181 - accuracy: 0.8760 - val_loss: 0.3293 - val_accuracy: 0.8750\n",
      "Epoch 425/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3187 - accuracy: 0.8733 - val_loss: 0.3344 - val_accuracy: 0.8804\n",
      "Epoch 426/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3191 - accuracy: 0.8774 - val_loss: 0.3295 - val_accuracy: 0.8750\n",
      "Epoch 427/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3196 - accuracy: 0.8733 - val_loss: 0.3317 - val_accuracy: 0.8750\n",
      "Epoch 428/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3220 - accuracy: 0.8719 - val_loss: 0.3324 - val_accuracy: 0.8750\n",
      "Epoch 429/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3220 - accuracy: 0.8747 - val_loss: 0.3316 - val_accuracy: 0.8750\n",
      "Epoch 430/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3192 - accuracy: 0.8760 - val_loss: 0.3387 - val_accuracy: 0.8750\n",
      "Epoch 431/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3223 - accuracy: 0.8719 - val_loss: 0.3299 - val_accuracy: 0.8750\n",
      "Epoch 432/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3238 - accuracy: 0.8665 - val_loss: 0.3403 - val_accuracy: 0.8696\n",
      "Epoch 433/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3197 - accuracy: 0.8760 - val_loss: 0.3297 - val_accuracy: 0.8750\n",
      "Epoch 434/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3179 - accuracy: 0.8787 - val_loss: 0.3373 - val_accuracy: 0.8750\n",
      "Epoch 435/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3185 - accuracy: 0.8747 - val_loss: 0.3312 - val_accuracy: 0.8750\n",
      "Epoch 436/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3196 - accuracy: 0.8760 - val_loss: 0.3357 - val_accuracy: 0.8804\n",
      "Epoch 437/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3250 - accuracy: 0.8665 - val_loss: 0.3319 - val_accuracy: 0.8804\n",
      "Epoch 438/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3223 - accuracy: 0.8747 - val_loss: 0.3238 - val_accuracy: 0.8750\n",
      "Epoch 439/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3280 - accuracy: 0.8692 - val_loss: 0.3439 - val_accuracy: 0.8696\n",
      "Epoch 440/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3154 - accuracy: 0.8733 - val_loss: 0.3206 - val_accuracy: 0.8750\n",
      "Epoch 441/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3177 - accuracy: 0.8733 - val_loss: 0.3525 - val_accuracy: 0.8696\n",
      "Epoch 442/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3256 - accuracy: 0.8665 - val_loss: 0.3260 - val_accuracy: 0.8804\n",
      "Epoch 443/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3185 - accuracy: 0.8774 - val_loss: 0.3443 - val_accuracy: 0.8696\n",
      "Epoch 444/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3203 - accuracy: 0.8733 - val_loss: 0.3284 - val_accuracy: 0.8804\n",
      "Epoch 445/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3192 - accuracy: 0.8733 - val_loss: 0.3355 - val_accuracy: 0.8804\n",
      "Epoch 446/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3197 - accuracy: 0.8706 - val_loss: 0.3284 - val_accuracy: 0.8804\n",
      "Epoch 447/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3192 - accuracy: 0.8760 - val_loss: 0.3367 - val_accuracy: 0.8750\n",
      "Epoch 448/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3189 - accuracy: 0.8774 - val_loss: 0.3254 - val_accuracy: 0.8804\n",
      "Epoch 449/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3174 - accuracy: 0.8774 - val_loss: 0.3393 - val_accuracy: 0.8750\n",
      "Epoch 450/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3171 - accuracy: 0.8787 - val_loss: 0.3296 - val_accuracy: 0.8859\n",
      "Epoch 451/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3182 - accuracy: 0.8774 - val_loss: 0.3300 - val_accuracy: 0.8859\n",
      "Epoch 452/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3169 - accuracy: 0.8774 - val_loss: 0.3288 - val_accuracy: 0.8804\n",
      "Epoch 453/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3172 - accuracy: 0.8774 - val_loss: 0.3316 - val_accuracy: 0.8804\n",
      "Epoch 454/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3202 - accuracy: 0.8747 - val_loss: 0.3366 - val_accuracy: 0.8804\n",
      "Epoch 455/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3218 - accuracy: 0.8760 - val_loss: 0.3277 - val_accuracy: 0.8804\n",
      "Epoch 456/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3242 - accuracy: 0.8638 - val_loss: 0.3424 - val_accuracy: 0.8696\n",
      "Epoch 457/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3294 - accuracy: 0.8760 - val_loss: 0.3271 - val_accuracy: 0.8804\n",
      "Epoch 458/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3163 - accuracy: 0.8774 - val_loss: 0.3524 - val_accuracy: 0.8641\n",
      "Epoch 459/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3168 - accuracy: 0.8760 - val_loss: 0.3233 - val_accuracy: 0.8804\n",
      "Epoch 460/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3219 - accuracy: 0.8719 - val_loss: 0.3370 - val_accuracy: 0.8804\n",
      "Epoch 461/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3182 - accuracy: 0.8760 - val_loss: 0.3297 - val_accuracy: 0.8859\n",
      "Epoch 462/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3193 - accuracy: 0.8733 - val_loss: 0.3346 - val_accuracy: 0.8804\n",
      "Epoch 463/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3186 - accuracy: 0.8747 - val_loss: 0.3328 - val_accuracy: 0.8804\n",
      "Epoch 464/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3218 - accuracy: 0.8733 - val_loss: 0.3442 - val_accuracy: 0.8696\n",
      "Epoch 465/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3227 - accuracy: 0.8692 - val_loss: 0.3281 - val_accuracy: 0.8859\n",
      "Epoch 466/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3177 - accuracy: 0.8774 - val_loss: 0.3277 - val_accuracy: 0.8859\n",
      "Epoch 467/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3159 - accuracy: 0.8760 - val_loss: 0.3416 - val_accuracy: 0.8696\n",
      "Epoch 468/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3197 - accuracy: 0.8733 - val_loss: 0.3236 - val_accuracy: 0.8804\n",
      "Epoch 469/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3208 - accuracy: 0.8747 - val_loss: 0.3333 - val_accuracy: 0.8804\n",
      "Epoch 470/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3164 - accuracy: 0.8774 - val_loss: 0.3375 - val_accuracy: 0.8804\n",
      "Epoch 471/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3164 - accuracy: 0.8774 - val_loss: 0.3285 - val_accuracy: 0.8859\n",
      "Epoch 472/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3266 - accuracy: 0.8747 - val_loss: 0.3362 - val_accuracy: 0.8804\n",
      "Epoch 473/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3272 - accuracy: 0.8706 - val_loss: 0.3353 - val_accuracy: 0.8804\n",
      "Epoch 474/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3235 - accuracy: 0.8706 - val_loss: 0.3284 - val_accuracy: 0.8859\n",
      "Epoch 475/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3178 - accuracy: 0.8733 - val_loss: 0.3427 - val_accuracy: 0.8696\n",
      "Epoch 476/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3195 - accuracy: 0.8801 - val_loss: 0.3260 - val_accuracy: 0.8859\n",
      "Epoch 477/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3179 - accuracy: 0.8774 - val_loss: 0.3370 - val_accuracy: 0.8804\n",
      "Epoch 478/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3168 - accuracy: 0.8787 - val_loss: 0.3287 - val_accuracy: 0.8859\n",
      "Epoch 479/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3202 - accuracy: 0.8760 - val_loss: 0.3425 - val_accuracy: 0.8696\n",
      "Epoch 480/600\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3176 - accuracy: 0.8774 - val_loss: 0.3264 - val_accuracy: 0.8859\n",
      "Epoch 481/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3164 - accuracy: 0.8787 - val_loss: 0.3425 - val_accuracy: 0.8696\n",
      "Epoch 482/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3202 - accuracy: 0.8787 - val_loss: 0.3292 - val_accuracy: 0.8859\n",
      "Epoch 483/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3157 - accuracy: 0.8760 - val_loss: 0.3413 - val_accuracy: 0.8696\n",
      "Epoch 484/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3174 - accuracy: 0.8760 - val_loss: 0.3283 - val_accuracy: 0.8859\n",
      "Epoch 485/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3179 - accuracy: 0.8774 - val_loss: 0.3284 - val_accuracy: 0.8859\n",
      "Epoch 486/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3171 - accuracy: 0.8774 - val_loss: 0.3333 - val_accuracy: 0.8804\n",
      "Epoch 487/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3209 - accuracy: 0.8760 - val_loss: 0.3287 - val_accuracy: 0.8859\n",
      "Epoch 488/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3190 - accuracy: 0.8638 - val_loss: 0.3417 - val_accuracy: 0.8696\n",
      "Epoch 489/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3171 - accuracy: 0.8760 - val_loss: 0.3218 - val_accuracy: 0.8750\n",
      "Epoch 490/600\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3233 - accuracy: 0.8706 - val_loss: 0.3369 - val_accuracy: 0.8804\n",
      "Epoch 491/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3224 - accuracy: 0.8719 - val_loss: 0.3301 - val_accuracy: 0.8859\n",
      "Epoch 492/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3173 - accuracy: 0.8760 - val_loss: 0.3349 - val_accuracy: 0.8804\n",
      "Epoch 493/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3165 - accuracy: 0.8774 - val_loss: 0.3317 - val_accuracy: 0.8859\n",
      "Epoch 494/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3162 - accuracy: 0.8774 - val_loss: 0.3322 - val_accuracy: 0.8859\n",
      "Epoch 495/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3167 - accuracy: 0.8774 - val_loss: 0.3337 - val_accuracy: 0.8804\n",
      "Epoch 496/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3164 - accuracy: 0.8774 - val_loss: 0.3322 - val_accuracy: 0.8804\n",
      "Epoch 497/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3156 - accuracy: 0.8774 - val_loss: 0.3248 - val_accuracy: 0.8859\n",
      "Epoch 498/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3171 - accuracy: 0.8760 - val_loss: 0.3372 - val_accuracy: 0.8804\n",
      "Epoch 499/600\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.3181 - accuracy: 0.8787 - val_loss: 0.3237 - val_accuracy: 0.8804\n",
      "Epoch 500/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3165 - accuracy: 0.8774 - val_loss: 0.3415 - val_accuracy: 0.8750\n",
      "Epoch 501/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3159 - accuracy: 0.8787 - val_loss: 0.3230 - val_accuracy: 0.8804\n",
      "Epoch 502/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3186 - accuracy: 0.8787 - val_loss: 0.3318 - val_accuracy: 0.8859\n",
      "Epoch 503/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3176 - accuracy: 0.8774 - val_loss: 0.3249 - val_accuracy: 0.8859\n",
      "Epoch 504/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3162 - accuracy: 0.8760 - val_loss: 0.3491 - val_accuracy: 0.8641\n",
      "Epoch 505/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3187 - accuracy: 0.8747 - val_loss: 0.3209 - val_accuracy: 0.8750\n",
      "Epoch 506/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3178 - accuracy: 0.8774 - val_loss: 0.3373 - val_accuracy: 0.8804\n",
      "Epoch 507/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3157 - accuracy: 0.8801 - val_loss: 0.3228 - val_accuracy: 0.8859\n",
      "Epoch 508/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3181 - accuracy: 0.8747 - val_loss: 0.3409 - val_accuracy: 0.8750\n",
      "Epoch 509/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3187 - accuracy: 0.8719 - val_loss: 0.3208 - val_accuracy: 0.8804\n",
      "Epoch 510/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3266 - accuracy: 0.8678 - val_loss: 0.3393 - val_accuracy: 0.8804\n",
      "Epoch 511/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3224 - accuracy: 0.8760 - val_loss: 0.3275 - val_accuracy: 0.8859\n",
      "Epoch 512/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3171 - accuracy: 0.8774 - val_loss: 0.3283 - val_accuracy: 0.8859\n",
      "Epoch 513/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3186 - accuracy: 0.8787 - val_loss: 0.3304 - val_accuracy: 0.8859\n",
      "Epoch 514/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3167 - accuracy: 0.8774 - val_loss: 0.3276 - val_accuracy: 0.8859\n",
      "Epoch 515/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3154 - accuracy: 0.8774 - val_loss: 0.3319 - val_accuracy: 0.8859\n",
      "Epoch 516/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3196 - accuracy: 0.8801 - val_loss: 0.3236 - val_accuracy: 0.8859\n",
      "Epoch 517/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3174 - accuracy: 0.8719 - val_loss: 0.3371 - val_accuracy: 0.8804\n",
      "Epoch 518/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3175 - accuracy: 0.8747 - val_loss: 0.3367 - val_accuracy: 0.8804\n",
      "Epoch 519/600\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3160 - accuracy: 0.8801 - val_loss: 0.3213 - val_accuracy: 0.8804\n",
      "Epoch 520/600\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3168 - accuracy: 0.8828 - val_loss: 0.3393 - val_accuracy: 0.8804\n",
      "Epoch 521/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3152 - accuracy: 0.8801 - val_loss: 0.3199 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 522/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3183 - accuracy: 0.8733 - val_loss: 0.3474 - val_accuracy: 0.8641\n",
      "Epoch 523/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3219 - accuracy: 0.8665 - val_loss: 0.3293 - val_accuracy: 0.8859\n",
      "Epoch 524/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3153 - accuracy: 0.8774 - val_loss: 0.3267 - val_accuracy: 0.8859\n",
      "Epoch 525/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3159 - accuracy: 0.8774 - val_loss: 0.3278 - val_accuracy: 0.8859\n",
      "Epoch 526/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3182 - accuracy: 0.8747 - val_loss: 0.3294 - val_accuracy: 0.8859\n",
      "Epoch 527/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3152 - accuracy: 0.8787 - val_loss: 0.3252 - val_accuracy: 0.8859\n",
      "Epoch 528/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3165 - accuracy: 0.8760 - val_loss: 0.3320 - val_accuracy: 0.8859\n",
      "Epoch 529/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3166 - accuracy: 0.8774 - val_loss: 0.3283 - val_accuracy: 0.8859\n",
      "Epoch 530/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3160 - accuracy: 0.8801 - val_loss: 0.3360 - val_accuracy: 0.8804\n",
      "Epoch 531/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3170 - accuracy: 0.8774 - val_loss: 0.3262 - val_accuracy: 0.8859\n",
      "Epoch 532/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3144 - accuracy: 0.8787 - val_loss: 0.3364 - val_accuracy: 0.8804\n",
      "Epoch 533/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3170 - accuracy: 0.8787 - val_loss: 0.3225 - val_accuracy: 0.8859\n",
      "Epoch 534/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3157 - accuracy: 0.8760 - val_loss: 0.3346 - val_accuracy: 0.8804\n",
      "Epoch 535/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3161 - accuracy: 0.8787 - val_loss: 0.3243 - val_accuracy: 0.8859\n",
      "Epoch 536/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3157 - accuracy: 0.8787 - val_loss: 0.3349 - val_accuracy: 0.8804\n",
      "Epoch 537/600\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3157 - accuracy: 0.8760 - val_loss: 0.3293 - val_accuracy: 0.8859\n",
      "Epoch 538/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3155 - accuracy: 0.8787 - val_loss: 0.3275 - val_accuracy: 0.8859\n",
      "Epoch 539/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3180 - accuracy: 0.8747 - val_loss: 0.3317 - val_accuracy: 0.8859\n",
      "Epoch 540/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3201 - accuracy: 0.8706 - val_loss: 0.3284 - val_accuracy: 0.8859\n",
      "Epoch 541/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3160 - accuracy: 0.8774 - val_loss: 0.3287 - val_accuracy: 0.8859\n",
      "Epoch 542/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3158 - accuracy: 0.8787 - val_loss: 0.3339 - val_accuracy: 0.8859\n",
      "Epoch 543/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3150 - accuracy: 0.8774 - val_loss: 0.3255 - val_accuracy: 0.8859\n",
      "Epoch 544/600\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.3152 - accuracy: 0.8774 - val_loss: 0.3332 - val_accuracy: 0.8859\n",
      "Epoch 545/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3151 - accuracy: 0.8787 - val_loss: 0.3308 - val_accuracy: 0.8859\n",
      "Epoch 546/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3157 - accuracy: 0.8774 - val_loss: 0.3265 - val_accuracy: 0.8859\n",
      "Epoch 547/600\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3214 - accuracy: 0.8706 - val_loss: 0.3294 - val_accuracy: 0.8859\n",
      "Epoch 548/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3203 - accuracy: 0.8733 - val_loss: 0.3296 - val_accuracy: 0.8859\n",
      "Epoch 549/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3263 - accuracy: 0.8774 - val_loss: 0.3335 - val_accuracy: 0.8859\n",
      "Epoch 550/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3262 - accuracy: 0.8665 - val_loss: 0.3361 - val_accuracy: 0.8804\n",
      "Epoch 551/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3429 - accuracy: 0.8651 - val_loss: 0.3244 - val_accuracy: 0.8859\n",
      "Epoch 552/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3252 - accuracy: 0.8624 - val_loss: 0.3525 - val_accuracy: 0.8641\n",
      "Epoch 553/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3285 - accuracy: 0.8706 - val_loss: 0.3189 - val_accuracy: 0.8750\n",
      "Epoch 554/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3415 - accuracy: 0.8542 - val_loss: 0.3314 - val_accuracy: 0.8859\n",
      "Epoch 555/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3310 - accuracy: 0.8665 - val_loss: 0.3227 - val_accuracy: 0.8859\n",
      "Epoch 556/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3231 - accuracy: 0.8569 - val_loss: 0.3422 - val_accuracy: 0.8696\n",
      "Epoch 557/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3165 - accuracy: 0.8747 - val_loss: 0.3187 - val_accuracy: 0.8750\n",
      "Epoch 558/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3194 - accuracy: 0.8774 - val_loss: 0.3388 - val_accuracy: 0.8750\n",
      "Epoch 559/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3196 - accuracy: 0.8760 - val_loss: 0.3244 - val_accuracy: 0.8859\n",
      "Epoch 560/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3141 - accuracy: 0.8801 - val_loss: 0.3359 - val_accuracy: 0.8804\n",
      "Epoch 561/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3146 - accuracy: 0.8787 - val_loss: 0.3271 - val_accuracy: 0.8859\n",
      "Epoch 562/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3144 - accuracy: 0.8760 - val_loss: 0.3298 - val_accuracy: 0.8859\n",
      "Epoch 563/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3147 - accuracy: 0.8787 - val_loss: 0.3331 - val_accuracy: 0.8859\n",
      "Epoch 564/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3160 - accuracy: 0.8801 - val_loss: 0.3260 - val_accuracy: 0.8859\n",
      "Epoch 565/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3149 - accuracy: 0.8774 - val_loss: 0.3282 - val_accuracy: 0.8859\n",
      "Epoch 566/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3152 - accuracy: 0.8801 - val_loss: 0.3289 - val_accuracy: 0.8859\n",
      "Epoch 567/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3145 - accuracy: 0.8787 - val_loss: 0.3236 - val_accuracy: 0.8859\n",
      "Epoch 568/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3171 - accuracy: 0.8774 - val_loss: 0.3289 - val_accuracy: 0.8859\n",
      "Epoch 569/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3229 - accuracy: 0.8692 - val_loss: 0.3279 - val_accuracy: 0.8859\n",
      "Epoch 570/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3173 - accuracy: 0.8760 - val_loss: 0.3233 - val_accuracy: 0.8859\n",
      "Epoch 571/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3140 - accuracy: 0.8774 - val_loss: 0.3414 - val_accuracy: 0.8696\n",
      "Epoch 572/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3195 - accuracy: 0.8719 - val_loss: 0.3161 - val_accuracy: 0.8750\n",
      "Epoch 573/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3205 - accuracy: 0.8733 - val_loss: 0.3447 - val_accuracy: 0.8696\n",
      "Epoch 574/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3198 - accuracy: 0.8801 - val_loss: 0.3257 - val_accuracy: 0.8859\n",
      "Epoch 575/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3153 - accuracy: 0.8760 - val_loss: 0.3307 - val_accuracy: 0.8859\n",
      "Epoch 576/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3145 - accuracy: 0.8774 - val_loss: 0.3330 - val_accuracy: 0.8859\n",
      "Epoch 577/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3145 - accuracy: 0.8787 - val_loss: 0.3302 - val_accuracy: 0.8859\n",
      "Epoch 578/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3161 - accuracy: 0.8787 - val_loss: 0.3209 - val_accuracy: 0.8804\n",
      "Epoch 579/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3167 - accuracy: 0.8801 - val_loss: 0.3321 - val_accuracy: 0.8859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 580/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3165 - accuracy: 0.8760 - val_loss: 0.3259 - val_accuracy: 0.8859\n",
      "Epoch 581/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3152 - accuracy: 0.8733 - val_loss: 0.3365 - val_accuracy: 0.8804\n",
      "Epoch 582/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3198 - accuracy: 0.8706 - val_loss: 0.3266 - val_accuracy: 0.8859\n",
      "Epoch 583/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3218 - accuracy: 0.8719 - val_loss: 0.3317 - val_accuracy: 0.8859\n",
      "Epoch 584/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3189 - accuracy: 0.8747 - val_loss: 0.3204 - val_accuracy: 0.8859\n",
      "Epoch 585/600\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3185 - accuracy: 0.8774 - val_loss: 0.3409 - val_accuracy: 0.8696\n",
      "Epoch 586/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3166 - accuracy: 0.8747 - val_loss: 0.3171 - val_accuracy: 0.8696\n",
      "Epoch 587/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3184 - accuracy: 0.8747 - val_loss: 0.3456 - val_accuracy: 0.8696\n",
      "Epoch 588/600\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3136 - accuracy: 0.8787 - val_loss: 0.3195 - val_accuracy: 0.8750\n",
      "Epoch 589/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3161 - accuracy: 0.8747 - val_loss: 0.3324 - val_accuracy: 0.8859\n",
      "Epoch 590/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3173 - accuracy: 0.8787 - val_loss: 0.3256 - val_accuracy: 0.8859\n",
      "Epoch 591/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3168 - accuracy: 0.8774 - val_loss: 0.3261 - val_accuracy: 0.8859\n",
      "Epoch 592/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3167 - accuracy: 0.8774 - val_loss: 0.3272 - val_accuracy: 0.8859\n",
      "Epoch 593/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3155 - accuracy: 0.8801 - val_loss: 0.3334 - val_accuracy: 0.8859\n",
      "Epoch 594/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3141 - accuracy: 0.8787 - val_loss: 0.3240 - val_accuracy: 0.8859\n",
      "Epoch 595/600\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3149 - accuracy: 0.8787 - val_loss: 0.3275 - val_accuracy: 0.8859\n",
      "Epoch 596/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3190 - accuracy: 0.8774 - val_loss: 0.3306 - val_accuracy: 0.8859\n",
      "Epoch 597/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3167 - accuracy: 0.8733 - val_loss: 0.3386 - val_accuracy: 0.8750\n",
      "Epoch 598/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3238 - accuracy: 0.8733 - val_loss: 0.3215 - val_accuracy: 0.8859\n",
      "Epoch 599/600\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3255 - accuracy: 0.8706 - val_loss: 0.3322 - val_accuracy: 0.8859\n",
      "Epoch 600/600\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3184 - accuracy: 0.8692 - val_loss: 0.3227 - val_accuracy: 0.8859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f9ee423d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model for 10 epochs\n",
    "model.fit(X_train_ds, Y_train_ds, batch_size=128, epochs=600, validation_data=(X_test_ds, Y_test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def deep_predict(heart_data):\n",
    "    numpy_data = np.array([[heart_data[0], heart_data[1], heart_data[2], heart_data[3], heart_data[4], heart_data[5], heart_data[6], heart_data[7], heart_data[8],\n",
    "                            heart_data[9],heart_data[10]]])\n",
    "    df = pd.DataFrame(data=numpy_data, columns=[\"Age\", \"Sex\",'ChestPainType', 'RestingBP', 'Cholesterol', 'FastingBS', 'RestingECG', 'MaxHR', 'ExerciseAngina', 'Oldpeak', 'ST_Slope'])\n",
    "    x = enc.get_encoded_df(df)\n",
    "    x = x.to_numpy().astype('float32') / 1000\n",
    "    return model.predict(x, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20890763]]\n"
     ]
    }
   ],
   "source": [
    "test_output = deep_predict([49,'F','NAP',160,180,0,'Normal',156,'N',1,'Flat'])\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90904486]]\n"
     ]
    }
   ],
   "source": [
    "test_output = deep_predict([31,'M','ASY',120,270,0,'Normal',153,'Y',1.5,'Flat'])\n",
    "print(test_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
