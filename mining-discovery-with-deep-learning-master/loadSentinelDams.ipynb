{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/remis/mining-discovery-with-deep-learning/blob/master/loadSentinelDams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9eysUOMdrzPq"
   },
   "source": [
    "# Creates image samples from Sentinel 2 collections\n",
    "\n",
    "This script is part of a research project published on the paper \"Mining and Tailings Dam Detection In Satellite Imagery Using Deep Learning\" by Remis Balaniuk, Olga Isupova and Steven Reece. This project was developed at the University of Oxford from September 2019 to February 2020.\n",
    "It was prepared to be used on the Google Colaboratory platform (see https://colab.research.google.com/notebooks/welcome.ipynb ).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vE1lo3lKgL3p"
   },
   "outputs": [],
   "source": [
    "# !pip install earthengine-api\n",
    "# !pip install geopandas\n",
    "import os\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MtPTLWyssv-t"
   },
   "source": [
    "The user must have an Google account and sign up to use the Google Earth Engine (see https://earthengine.google.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "-5HIkyT5gWKW",
    "outputId": "9f39cbaf-aafb-4788-f81d-fd7b0402ca9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=-jhQFHZx8CEjrhZ1jDCssyKpe4XjNby1pozpfpwtKFY&tc=noOKWXMUXEeLFTzZDUZzogoJQS8e8O76sUODhTqlq4s&cc=frPnWOcukxsqgnfv-Ghp1Pk6oPhhqCu4s9f0jLu6g58>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=-jhQFHZx8CEjrhZ1jDCssyKpe4XjNby1pozpfpwtKFY&tc=noOKWXMUXEeLFTzZDUZzogoJQS8e8O76sUODhTqlq4s&cc=frPnWOcukxsqgnfv-Ghp1Pk6oPhhqCu4s9f0jLu6g58</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you\n",
       "        should paste in the box below</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter verification code: 160569566253-5h2e0udg8puhomist406tnudhrs7k3pp.apps.googleusercontent.com\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'client_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mee\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# '4/1AX4XfWhI7Z01bqf5Vq4F8I-0vnWg2eDLfSavUq5PEJnxOv--Nrby3WpEP6Q'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Trigger the authentication flow.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mee\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAuthenticate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Pycharm Projects/Anaconda/Machine-Learning/ml-env/lib/python3.8/site-packages/ee/__init__.py:96\u001b[0m, in \u001b[0;36mAuthenticate\u001b[0;34m(authorization_code, quiet, code_verifier, auth_mode)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mAuthenticate\u001b[39m(\n\u001b[1;32m     79\u001b[0m     authorization_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m     quiet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     81\u001b[0m     code_verifier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     82\u001b[0m     auth_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     83\u001b[0m   \u001b[38;5;124;03m\"\"\"Prompts the user to authorize access to Earth Engine via OAuth2.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m      None - a default mode is chosen based on your environment.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m   \u001b[43moauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthenticate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauthorization_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_verifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Pycharm Projects/Anaconda/Machine-Learning/ml-env/lib/python3.8/site-packages/ee/oauth.py:382\u001b[0m, in \u001b[0;36mauthenticate\u001b[0;34m(cli_authorization_code, quiet, cli_code_verifier, auth_mode)\u001b[0m\n\u001b[1;32m    379\u001b[0m   _display_auth_instructions_with_print(auth_url)\n\u001b[1;32m    380\u001b[0m _open_new_browser(auth_url)\n\u001b[0;32m--> 382\u001b[0m \u001b[43m_obtain_and_write_token\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_verifier\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Pycharm Projects/Anaconda/Machine-Learning/ml-env/lib/python3.8/site-packages/ee/oauth.py:182\u001b[0m, in \u001b[0;36m_obtain_and_write_token\u001b[0;34m(auth_code, code_verifier)\u001b[0m\n\u001b[1;32m    180\u001b[0m   fetch_client \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mRequest(FETCH_URL, data\u001b[38;5;241m=\u001b[39mdata, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m    181\u001b[0m   fetched_info \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(request\u001b[38;5;241m.\u001b[39murlopen(fetch_client)\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[0;32m--> 182\u001b[0m   client_info \u001b[38;5;241m=\u001b[39m {k: fetched_info[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_secret\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m    183\u001b[0m   scopes \u001b[38;5;241m=\u001b[39m fetched_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscopes\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m SCOPES\n\u001b[1;32m    184\u001b[0m token \u001b[38;5;241m=\u001b[39m request_token(auth_code\u001b[38;5;241m.\u001b[39mstrip(), code_verifier, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_info)\n",
      "File \u001b[0;32m~/Documents/Pycharm Projects/Anaconda/Machine-Learning/ml-env/lib/python3.8/site-packages/ee/oauth.py:182\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    180\u001b[0m   fetch_client \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mRequest(FETCH_URL, data\u001b[38;5;241m=\u001b[39mdata, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m    181\u001b[0m   fetched_info \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(request\u001b[38;5;241m.\u001b[39murlopen(fetch_client)\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[0;32m--> 182\u001b[0m   client_info \u001b[38;5;241m=\u001b[39m {k: \u001b[43mfetched_info\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_secret\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m    183\u001b[0m   scopes \u001b[38;5;241m=\u001b[39m fetched_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscopes\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m SCOPES\n\u001b[1;32m    184\u001b[0m token \u001b[38;5;241m=\u001b[39m request_token(auth_code\u001b[38;5;241m.\u001b[39mstrip(), code_verifier, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_info)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'client_id'"
     ]
    }
   ],
   "source": [
    "# Import the Earth Engine library.\n",
    "import ee\n",
    "# '4/1AX4XfWhI7Z01bqf5Vq4F8I-0vnWg2eDLfSavUq5PEJnxOv--Nrby3WpEP6Q'\n",
    "# Trigger the authentication flow.\n",
    "ee.Authenticate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tO2PBWWCDih8"
   },
   "source": [
    "Image samples will be saved on the user Google Drive. The drive must be mounted before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAoS6bhLgXI-"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/ernestopoku-kwarteng/Documents/Pycharm Projects/Anaconda/Machine-Learning/mining-discovery-with-deep-learning-master/loadSentinelDams.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ernestopoku-kwarteng/Documents/Pycharm%20Projects/Anaconda/Machine-Learning/mining-discovery-with-deep-learning-master/loadSentinelDams.ipynb#ch0000006?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ernestopoku-kwarteng/Documents/Pycharm%20Projects/Anaconda/Machine-Learning/mining-discovery-with-deep-learning-master/loadSentinelDams.ipynb#ch0000006?line=1'>2</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekYAZNg2gvte"
   },
   "outputs": [],
   "source": [
    "# Import the Earth Engine Python Package\n",
    "import ee\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S5lgF-yhEC-n"
   },
   "outputs": [],
   "source": [
    "# Initialize the Earth Engine object, using the authentication credentials.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXGrWxx9ibuL"
   },
   "outputs": [],
   "source": [
    "# Cloud masking function for Sentinel-2.\n",
    "def maskS2clouds(image):\n",
    "  cloudShadowBitMask = ee.Number(2).pow(3).int()\n",
    "  cloudsBitMask = ee.Number(2).pow(5).int()\n",
    "  qa = image.select('QA60')\n",
    "  mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(\n",
    "    qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
    "  return image.updateMask(mask).select(bands).divide(10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QaROQmT4Oyw4"
   },
   "source": [
    "Editing the next cell the user can select the spectral bands to be included on the image patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlg6wqlsiU4p"
   },
   "outputs": [],
   "source": [
    "# Use these bands for prediction.\n",
    "bands = ['B1', 'B2', 'B3', 'B4', 'B5','B6', 'B7', 'B8', 'B9', 'B10', 'B11', 'B12']\n",
    "\n",
    "# Use Sentinel 2 surface reflectance data.\n",
    "sentinel = ee.ImageCollection(\"COPERNICUS/S2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NfKWam0gHuMu"
   },
   "source": [
    "Editing the next cell the user can select the time interval (filterDate) and the cloud cover percentage ('CLOUDY_PIXEL_PERCENTAGE') to filter the images used on compose the patches. The shorter the interval the greater the chances to have pixels with no data to display. Regions with frequent cloud cover, like the rain forest, will require a long interval to ensure a complete pixel set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fwlGdgKLjFwW"
   },
   "outputs": [],
   "source": [
    "# The image input data is cloud-masked median composite.\n",
    "image = sentinel.filterDate('2018-01-01','2020-01-01').filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', 20)).map(maskS2clouds).median().toFloat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xJIw1aFOD2ZE"
   },
   "source": [
    "On the following the user will be able to choose a csv file from his Google Drive root containing the coordinates (latitude and longitude) of the spots from which he wants to extract the image patches. Additionally, he will be prompted to inform the columns separator used in the csv file. \n",
    "\n",
    "The polygons delimiting the areas of interest described on the csv file can be defined using one of the following schemes:\n",
    "\n",
    "1: using two pairs of coordinates indicating the lower-left  (souththwest) and the upper right (northeast) corners of the polygon;\n",
    "\n",
    "2: defining the coordinates of a central point and the length of the side of a square defined around that point.\n",
    "\n",
    "The user will be prompted to inform which scheme should be used to read the csv file (all records on the file should use the same scheme).\n",
    "\n",
    "A last column on the csv file should be used to inform a class name for the sample. This class name will be used as prefix to name the image files.\n",
    "\n",
    "The csv records should look like this:\n",
    "\n",
    "####-column separator =';' and scheme 1:\n",
    "\n",
    "> lower left y latitude; lower left x longitude; upper right y latitude; upper right x longitude;  class\n",
    "\n",
    "> -20.893706;-45.271998;-18.854222;-41.958905;area1\n",
    "\n",
    "\n",
    "####-column separator =';' and scheme 2:\n",
    "> central point latitude; central point longitude; class name\n",
    "\n",
    ">-23.82113889;-50.42022222;dam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTOhU5NdjMzU"
   },
   "outputs": [],
   "source": [
    "def offset(lat,lon,x,y):\n",
    "\n",
    "\t#Earthâ€™s radius, sphere\n",
    "\tR=6378137\n",
    "\n",
    "\t#Coordinate offsets in radians\n",
    "\tdLat = x/R\n",
    "\tdLon = y/(R*math.cos(math.pi*lat/180))\n",
    "\n",
    "\treturn lat + dLat * 180/math.pi, lon + dLon * 180/math.pi\n",
    " \n",
    "\n",
    "def exportImage(data,scheme,size=0):\n",
    "\n",
    "\t# Loop the csv file.\n",
    "\n",
    "\tfor d in range(data.shape[0]):\n",
    "\n",
    "\t\tif scheme == 2:\t\n",
    "\t\t\tx = data[d][0]\n",
    "\t\t\ty = data[d][1]\n",
    "\n",
    "\t\t\tllx , lly = offset(x,y,-size/2,-size/2)\n",
    "\t\t\turx , ury = offset(x,y,size/2,\tsize/2)\n",
    "\n",
    "\t\t\tlabel = data[d][2]\n",
    "\t \n",
    "\t\telse:\n",
    "\n",
    "\t\t\tllx = data[d][0]\n",
    "\t\t\tlly = data[d][1]\n",
    "\t\t\turx = data[d][2]\n",
    "\t\t\tury = data[d][3]\t\n",
    "\n",
    "\t\t\tlabel = data[d][4]\t\n",
    "\n",
    "\t\tgeometry = [[llx,lly], [llx,ury], [urx,ury], [urx,lly]]\n",
    "\n",
    "\t\ttask_config = {\n",
    "\t    'scale':  10 ,\n",
    "\t    'region': geometry\n",
    "\t    }\n",
    "\t\t\n",
    "\t\tname = label + str(d)\n",
    "\t\t# Create a task.\n",
    "\t\ttask = ee.batch.Export.image(image, name, task_config)\n",
    "\n",
    "\t\t# Send the task to the earth engine.\n",
    "\t\ttask.start()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a7rA0mUOdVo0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ernestopoku-kwarteng/Documents/Pycharm Projects/Anaconda/Machine-Learning/mining-discovery-with-deep-learning-master/data\n",
      "Choose your file:\n",
      "Not a number\n",
      "csv separator? (typically ';' or ',')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ernestopoku-kwarteng/Documents/Pycharm Projects/Anaconda/Machine-Learning/mining-discovery-with-deep-learning-master/loadSentinelDams.ipynb Cell 17'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ernestopoku-kwarteng/Documents/Pycharm%20Projects/Anaconda/Machine-Learning/mining-discovery-with-deep-learning-master/loadSentinelDams.ipynb#ch0000016?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcsv separator? (typically \u001b[39m\u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ernestopoku-kwarteng/Documents/Pycharm%20Projects/Anaconda/Machine-Learning/mining-discovery-with-deep-learning-master/loadSentinelDams.ipynb#ch0000016?line=20'>21</a>\u001b[0m sep\u001b[39m=\u001b[39m\u001b[39minput\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mInput:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ernestopoku-kwarteng/Documents/Pycharm%20Projects/Anaconda/Machine-Learning/mining-discovery-with-deep-learning-master/loadSentinelDams.ipynb#ch0000016?line=22'>23</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(files[r\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], sep\u001b[39m=\u001b[39m sep)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ernestopoku-kwarteng/Documents/Pycharm%20Projects/Anaconda/Machine-Learning/mining-discovery-with-deep-learning-master/loadSentinelDams.ipynb#ch0000016?line=23'>24</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ernestopoku-kwarteng/Documents/Pycharm%20Projects/Anaconda/Machine-Learning/mining-discovery-with-deep-learning-master/loadSentinelDams.ipynb#ch0000016?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],\u001b[39m\"\u001b[39m\u001b[39mrecords with\u001b[39m\u001b[39m\"\u001b[39m,data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "#MAIN WORKFLOW\n",
    "\n",
    "# assuming the csv file on the My drive root folder (change the %cd if it is not the case)\n",
    "%cd /content/drive/My Drive/\n",
    "files = []\n",
    "count=0\n",
    "for f in os.listdir('./'):\n",
    "  name, ext = os.path.splitext(f)\n",
    "  if ext == '.csv':\n",
    "    files.append(f)\n",
    "    count+=1\n",
    "    print(count,\":\",f)\n",
    "\n",
    "print(\"Choose your file:\")\n",
    "try:\n",
    "  r=int(input('Input:'))\n",
    "except ValueError:\n",
    "  print(\"Not a number\")\n",
    "\n",
    "print(\"csv separator? (typically ';' or ',')\")\n",
    "sep=input('Input:')\n",
    "\n",
    "data = pd.read_csv(files[r-1], sep= sep)\n",
    "data = data.values\n",
    "\n",
    "print(data.shape[0],\"records with\",data.shape[1],\"columns\")\n",
    "\n",
    "if data.shape[1]==3:\n",
    "  print(\"Central point scheme. Please inform the square side length (in meters):\")\n",
    "  try:\n",
    "    size=int(input('Input:'))\n",
    "  except ValueError:\n",
    "    print(\"Not a number\")\n",
    "  exportImage(data,2,size)\n",
    "elif data.shape[1]==5:\n",
    "  exportImage(data,1)\n",
    "else:\n",
    "  print(\"Invalid csv file!\")\n",
    "  sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mBTSvF9jyJ4D"
   },
   "source": [
    "If the script was succesfull the tasks should be visible on Google Earth Engine code editor (https://code.earthengine.google.com/) interface. The user must log on to authorize the tasks execution."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "loadSentinelDams.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
